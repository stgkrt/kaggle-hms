import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms

print("torch version", torch.__version__)
# ----------------------------------------------------------
# ハイパーパラメータなどの設定値
num_epochs = 10  # 学習を繰り返す回数
num_batch = 100  # 一度に処理する画像の枚数
learning_rate = 0.001  # 学習率
image_size = 28 * 28  # 画像の画素数(幅x高さ)

# GPU(CUDA)が使えるかどうか？
device = "cuda" if torch.cuda.is_available() else "cpu"

print("using device = ", device)
# ----------------------------------------------------------
# 学習用／評価用のデータセットの作成

# 変換方法の指定
transform = transforms.Compose([transforms.ToTensor()])

# MNISTデータの取得
# https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST
# 学習用
train_dataset = datasets.MNIST(
    "./data",  # データの保存先
    train=True,  # 学習用データを取得する
    download=True,  # データが無い時にダウンロードする
    transform=transform,  # テンソルへの変換など
)
# 評価用
test_dataset = datasets.MNIST("./data", train=False, transform=transform)

# データローダー
train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=num_batch, shuffle=True
)
test_dataloader = torch.utils.data.DataLoader(
    test_dataset, batch_size=num_batch, shuffle=True
)


class Net(nn.Module):
    def __init__(self, input_size, output_size):
        super(Net, self).__init__()

        self.fc1 = nn.Linear(input_size, 100)
        self.fc2 = nn.Linear(100, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = torch.sigmoid(x)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


# ----------------------------------------------------------
# ニューラルネットワークの生成
model = Net(image_size, 10).to(device)

# ----------------------------------------------------------
# 損失関数の設定
criterion = nn.CrossEntropyLoss()

# ----------------------------------------------------------
# 最適化手法の設定
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# ----------------------------------------------------------
# 学習
model.train()  # モデルを訓練モードにする

for epoch in range(num_epochs):  # 学習を繰り返し行う
    loss_sum = 0.0  # type: ignore

    for inputs, labels in train_dataloader:

        # GPUが使えるならGPUにデータを送る
        inputs = inputs.to(device)
        labels = labels.to(device)

        # optimizerを初期化
        optimizer.zero_grad()

        # ニューラルネットワークの処理を行う
        inputs = inputs.view(-1, image_size)  # 画像データ部分を一次元へ並び変える
        outputs = model(inputs)

        # 損失(出力とラベルとの誤差)の計算
        loss = criterion(outputs, labels)
        loss_sum += loss.item()

        # 勾配の計算
        loss.backward()

        # 重みの更新
        optimizer.step()

    # 学習状況の表示
    loss_value = float(loss_sum)  # type :ignore
    log_str = f"Epoch: {epoch+1}/{num_epochs}"
    log_str += f", loss: {loss_value/ len(train_dataloader)}"
    print(log_str)

    # モデルの重みの保存
    torch.save(model.state_dict(), "model_weights.pth")

# ----------------------------------------------------------
# 評価
model.eval()  # モデルを評価モードにする

loss_sum = 0
correct = 0

with torch.no_grad():
    for inputs, labels in test_dataloader:

        # GPUが使えるならGPUにデータを送る
        inputs = inputs.to(device)
        labels = labels.to(device)

        # ニューラルネットワークの処理を行う
        inputs = inputs.view(-1, image_size)  # 画像データ部分を一次元へ並び変える
        outputs = model(inputs)

        # 損失(出力とラベルとの誤差)の計算
        loss_sum += criterion(outputs, labels)

        # 正解の値を取得
        pred = outputs.argmax(1)
        # 正解数をカウント
        correct += pred.eq(labels.view_as(pred)).sum().item()

log_str = f"Loss: {loss_sum / len(test_dataloader)}"
log_str += f"Accuracy: {100*correct/len(test_dataset)}% ({correct}/{len(test_dataset)})"
print(log_str)
