{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b56142",
   "metadata": {
    "papermill": {
     "duration": 0.009102,
     "end_time": "2024-03-23T07:12:14.352782",
     "exception": false,
     "start_time": "2024-03-23T07:12:14.343680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Features+Head Ensemble Starter [LB 0.34] for HMS Brain Comp\n",
    "We can train 9 model and data variations: (all models included)\n",
    "\n",
    "**The Ensemble achieves LB 0.34**\n",
    "\n",
    "| MODEL | DATA TYPE | CV | LB |TRAINING TIME| NOTES |\n",
    "|----------------|-----------|----------|---|--|--|\n",
    "| EfficientNetB2 | K | 0.6123 | 0.41 | 2 hours and 58 minutes |K: Kaggle's spectrograms|\n",
    "| EfficientNetB2 | E | 0.6288 | 0.39 | 2 hours and 57 minutes |E: EEG's spectrograms|\n",
    "| WaveNet | R | 0.6992 | 0.41 | 3 hours and 35 minutes |R: Raw EEG signals|\n",
    "| EfficientNetB2 | KE | 0.5646 | 0.37 | 3 hours |KE: Kaggle's and EEG's spectrograms|\n",
    "| EfficientNetB2 + WaveNet | KR | 0.5912 | 0.39 | 4 hours and 20 minutes |KR: Kaggle's spectrograms and Raw EEG signals|\n",
    "| EfficientNetB2 + WaveNet | ER | 0.6085 | 0.38 | 4 hours and 22 minutes |ER: EEG's spectrograms and Raw EEG signals|\n",
    "| EfficientNetB2 + WaveNet | KER | - | 0.36 | 4 hours and 30 minutes |KER: Kaggle's, EEG's spectrograms and Raw EEG signals|\n",
    "| EfficientNetB2 | K+E | 0.5738 | 0.37 | 5 hours and 42 minutes |K+E: Data spectrogram augmentation|\n",
    "| EfficientNetB2 | K+E+KE | | 0.36 | 8 hours and 42 minutes |K+E+KE: Data spectrogram augmentation|\n",
    "\n",
    "Great discussion [here][5] by @KOLOO that led to the latest scores!\n",
    "\n",
    "Features+Head Starter uses Chris Deotte's Kaggle dataset [here][1]. Also Uses Chris's EEG spectrograms [here][3] (modified version). The Raw EEG signals can be found [here][6]. This notebook is a direct descendent of Chris's notebooks [EfficientNet][2] and [WaveNet][4]\n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/cdeotte/brain-spectrograms\n",
    "[2]: https://www.kaggle.com/code/cdeotte/efficientnetb2-starter-lb-0-57\n",
    "[3]: https://www.kaggle.com/datasets/nartaa/eeg-spectrograms\n",
    "[4]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/468684\n",
    "[5]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477461\n",
    "[6]: https://www.kaggle.com/datasets/nartaa/hms-eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c047782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:12:14.371915Z",
     "iopub.status.busy": "2024-03-23T07:12:14.371158Z",
     "iopub.status.idle": "2024-03-23T07:12:39.437987Z",
     "shell.execute_reply": "2024-03-23T07:12:39.436929Z"
    },
    "papermill": {
     "duration": 25.078845,
     "end_time": "2024-03-23T07:12:39.440290",
     "exception": false,
     "start_time": "2024-03-23T07:12:14.361445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os, random\n",
    "import yaml\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "import albumentations as albu\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd, numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "import tensorflow.keras.backend as K, gc\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "FOLD_NUM = 5\n",
    "\n",
    "\n",
    "LOAD_BACKBONE_FROM = '/kaggle/input/efficientnetb-tf-keras/EfficientNetB2.h5'\n",
    "LOAD_MODELS_FROM = '/kaggle/input/features-head-starter-models'\n",
    "HMS_PATH = '/kaggle/input/hms-harmful-brain-activity-classification'\n",
    "MODEL_DATA_TYPE = 'ER'\n",
    "MODEL = {MODEL_DATA_TYPE: 52} # Setup the model for Training\n",
    "for DATA_TYPE in MODEL: pass # K|E|R|KE|KR|ER|KER|K+E|K+E+KE\n",
    "USE_PROCESSED = True # Use processed downsampled Raw EEG \n",
    "\n",
    "TEST_MODE = False # USE 500 samples for quick testing\n",
    "TEST_ENSEMBLE = False # Local Ensemble CV Testing\n",
    "SUBMISSION = False\n",
    "\n",
    "# Setup for ensemble\n",
    "ENSEMBLE = True\n",
    "MODELS = {\n",
    "          'K'     : 43, # 'LB':0.41 Kaggle's spectrogram model version\n",
    "          'E'     : 42, # 'LB':0.39 EEG's spectrogram model version\n",
    "          'R'     : 37, # 'LB':0.41 EEG's Raw wavenet model version, trained on single GPU\n",
    "          'KE'    : 47, # 'LB':0.37 Kaggle's and EEG's spectrogram model version\n",
    "          'KR'    : 48, # 'LB':0.39 Kaggle's spectrogram and Raw model version\n",
    "          'ER'    : 49, # 'LB':0.38 EEG's spectrogram and Raw model version\n",
    "          'KER'   : 50, # 'LB':0.36 EEG's, Kaggle's spectrograms and Raw model version\n",
    "          'K+E'   : 51, # 'LB':0.37 Data spectrogram augmentation model version\n",
    "          'K+E+KE': 52, # 'LB':0.36 Data spectrogram augmentation model version\n",
    "         }\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# USE SINGLE GPU, MULTIPLE GPUS \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# WE USE MIXED PRECISION\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "if len(gpus)>1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Using {len(gpus)} GPUs')\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f'Using {len(gpus)} GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6444aba",
   "metadata": {
    "papermill": {
     "duration": 0.008516,
     "end_time": "2024-03-23T07:12:39.457967",
     "exception": false,
     "start_time": "2024-03-23T07:12:39.449451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and create Non-Overlapping Eeg Id Train Data\n",
    "The competition data description says that test data does not have multiple crops from the same `eeg_id`. Therefore we will train and validate using only 1 crop per `eeg_id`. There is a discussion about this [here][1].\n",
    "\n",
    "[1]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0192e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:12:39.477252Z",
     "iopub.status.busy": "2024-03-23T07:12:39.476130Z",
     "iopub.status.idle": "2024-03-23T07:12:39.931020Z",
     "shell.execute_reply": "2024-03-23T07:12:39.930049Z"
    },
    "papermill": {
     "duration": 0.466757,
     "end_time": "2024-03-23T07:12:39.933319",
     "exception": false,
     "start_time": "2024-03-23T07:12:39.466562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "\n",
    "def eeg_from_parquet(parquet_path):\n",
    "\n",
    "    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows-10_000)//2\n",
    "    eeg = eeg.iloc[offset:offset+10_000]\n",
    "    data = np.zeros((10_000,len(FEATS2)))\n",
    "    for j,col in enumerate(FEATS2):\n",
    "        \n",
    "        # FILL NAN\n",
    "        x = eeg[col].values.astype('float32')\n",
    "        m = np.nanmean(x)\n",
    "        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "        else: x[:] = 0\n",
    "        \n",
    "        data[:,j] = x\n",
    "\n",
    "    return data\n",
    "\n",
    "def add_kl(data):\n",
    "    labels = data[TARGETS].values + 1e-5\n",
    "    data['kl'] = tf.keras.losses.KLDivergence(reduction='none')(\n",
    "        np.array([[1/6]*6]*len(data)),labels)\n",
    "    return data\n",
    "    \n",
    "if not SUBMISSION:\n",
    "    train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train_3to20.csv')\n",
    "    TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    META = ['spectrogram_id','spectrogram_label_offset_seconds','patient_id','expert_consensus']\n",
    "    train = train.groupby('eeg_id')[META+TARGETS\n",
    "                           ].agg({**{m:'first' for m in META},**{t:'sum' for t in TARGETS}}).reset_index() \n",
    "    train[TARGETS] = train[TARGETS]/train[TARGETS].values.sum(axis=1,keepdims=True)\n",
    "    train.columns = ['eeg_id','spec_id','offset','patient_id','target'] + TARGETS\n",
    "    train = add_kl(train)\n",
    "    print(train.head(1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb06d2",
   "metadata": {
    "papermill": {
     "duration": 0.008657,
     "end_time": "2024-03-23T07:12:39.951504",
     "exception": false,
     "start_time": "2024-03-23T07:12:39.942847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read Train Spectrograms and EEGs\n",
    "\n",
    "We can read 3 file from Chris's [Kaggle dataset here][1] which contains all the 11k spectrograms. From Chris's modified EEG spectrogram [here][2]. From Raw EEG signals [here][3]\n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/cdeotte/brain-spectrograms\n",
    "[2]: https://www.kaggle.com/datasets/nartaa/eeg-spectrograms\n",
    "[3]: https://www.kaggle.com/datasets/nartaa/hms-eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abac2d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:12:39.970496Z",
     "iopub.status.busy": "2024-03-23T07:12:39.969759Z",
     "iopub.status.idle": "2024-03-23T07:15:38.624967Z",
     "shell.execute_reply": "2024-03-23T07:15:38.623917Z"
    },
    "papermill": {
     "duration": 178.676019,
     "end_time": "2024-03-23T07:15:38.636259",
     "exception": false,
     "start_time": "2024-03-23T07:12:39.960240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if not SUBMISSION:\n",
    "    # FOR TESTING SET TEST_MODE TO TRUE\n",
    "    if TEST_MODE:\n",
    "        USE_PROCESSED = False\n",
    "        train = train.sample(500,random_state=42).reset_index(drop=True)\n",
    "        spectrograms = {}\n",
    "        for i,e in enumerate(train.spec_id.values):\n",
    "            if i%100==0: print(i,', ',end='')\n",
    "            x = pd.read_parquet(f'{HMS_PATH}/train_spectrograms/{e}.parquet')\n",
    "            spectrograms[e] = x.values\n",
    "        all_eegs = {}\n",
    "        for i,e in enumerate(train.eeg_id.values):\n",
    "            if i%100==0: print(i,', ',end='')\n",
    "            x = np.load(f'/kaggle/input/eeg-spectrograms/EEG_Spectrograms/{e}.npy')\n",
    "            all_eegs[e] = x\n",
    "        all_raw_eegs = {}\n",
    "        for i,e in enumerate(train.eeg_id.values):\n",
    "            if i%100==0: print(i,', ',end='')\n",
    "            x = eeg_from_parquet(f'{HMS_PATH}/train_eegs/{e}.parquet')              \n",
    "            all_raw_eegs[e] = x\n",
    "    else:\n",
    "        spectrograms = None\n",
    "        all_eegs = None\n",
    "        all_raw_eegs = None\n",
    "        if TEST_ENSEMBLE or DATA_TYPE in ['K','KE','K+E','K+E+KE','KR','KER']:\n",
    "            spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()\n",
    "        if TEST_ENSEMBLE or DATA_TYPE in ['E','KE','K+E','K+E+KE','ER','KER']:\n",
    "            all_eegs = np.load('/kaggle/input/eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()\n",
    "        if TEST_ENSEMBLE or DATA_TYPE in ['R','KR','ER','KER']:\n",
    "            if USE_PROCESSED:\n",
    "                all_raw_eegs = np.load('/kaggle/input/hms-eeg/eegs_processed.npy',allow_pickle=True).item()\n",
    "            else:\n",
    "                all_raw_eegs = np.load('/kaggle/input/hms-eeg/eegs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc09898",
   "metadata": {
    "papermill": {
     "duration": 0.008743,
     "end_time": "2024-03-23T07:15:38.654501",
     "exception": false,
     "start_time": "2024-03-23T07:15:38.645758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATA GENERATOR\n",
    "This data generator outputs 512x512x3, the spectrogram and eeg images are concatenated all togother in a single image. For using data augmention you can set `augment = True` when creating the train data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6be764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:15:38.673971Z",
     "iopub.status.busy": "2024-03-23T07:15:38.673640Z",
     "iopub.status.idle": "2024-03-23T07:15:38.745440Z",
     "shell.execute_reply": "2024-03-23T07:15:38.744582Z"
    },
    "papermill": {
     "duration": 0.084064,
     "end_time": "2024-03-23T07:15:38.747365",
     "exception": false,
     "start_time": "2024-03-23T07:15:38.663301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "FEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2']]\n",
    "    \n",
    "class DataGenerator():\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, specs=None, eeg_specs=None, raw_eegs=None , augment=False, mode='train', data_type=DATA_TYPE): \n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.data_type = data_type\n",
    "        self.data = self.build_data(data.copy())\n",
    "        self.specs = specs\n",
    "        self.eeg_specs = eeg_specs\n",
    "        self.raw_eegs = raw_eegs\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def build_data(self,data):\n",
    "        if self.data_type in ['K+E']:\n",
    "            data_dup = pd.concat([data] * 2, ignore_index=True)\n",
    "            data_dup.loc[:len(data),'data_type'] = 'K'\n",
    "            data_dup.loc[len(data):,'data_type'] = 'E'\n",
    "            data = data_dup\n",
    "        elif self.data_type in ['K+E+KE']:\n",
    "            data_trp = pd.concat([data] * 3, ignore_index=True)\n",
    "            data_trp.loc[:len(data),'data_type'] = 'K'\n",
    "            data_trp.loc[len(data):len(data)*2,'data_type'] = 'E'\n",
    "            data_trp.loc[len(data)*2:,'data_type'] = 'KE'\n",
    "            data = data_trp\n",
    "        else:\n",
    "            data['data_type'] = self.data_type\n",
    "        return data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.data_generation(index)\n",
    "        if self.augment: X = self.augmentation(X)\n",
    "        return X, y\n",
    "    \n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "            \n",
    "            if i == self.__len__()-1:\n",
    "                self.on_epoch_end()\n",
    "                \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode=='train': \n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def data_generation(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        if row.data_type == 'KE':\n",
    "            X,y = self.generate_all_specs(index)\n",
    "        elif row.data_type in ['K','E']:\n",
    "            X,y = self.generate_specs(index)\n",
    "        elif row.data_type == 'R':\n",
    "            X,y = self.generate_raw(index)\n",
    "        elif row.data_type in ['ER','KR']:\n",
    "            X1,y = self.generate_specs(index)\n",
    "            X2,y = self.generate_raw(index)\n",
    "            X = (X1,X2)\n",
    "        elif row.data_type in ['KER']:\n",
    "            X1,y = self.generate_all_specs(index)\n",
    "            X2,y = self.generate_raw(index)\n",
    "            X = (X1,X2)\n",
    "        return X,y\n",
    "    \n",
    "    def generate_all_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "        \n",
    "        eeg = self.eeg_specs[row.eeg_id]\n",
    "        spec = self.specs[row.spec_id]\n",
    "        \n",
    "        imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "        img = np.stack(imgs,axis=-1)\n",
    "        # LOG TRANSFORM SPECTROGRAM\n",
    "        img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "        img = np.log(img)\n",
    "            \n",
    "        # STANDARDIZE PER IMAGE\n",
    "        img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2] # RL_k\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1] # LP_k\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n",
    "        \n",
    "        # EEG\n",
    "        img = eeg\n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,2] # RL_e\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,1] # LP_e\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n",
    "\n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "        \n",
    "        if row.data_type in ['E','ER']:\n",
    "            img = self.eeg_specs[row.eeg_id]\n",
    "        elif row.data_type in ['K','KR']:\n",
    "            spec = self.specs[row.spec_id]\n",
    "            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "            img = np.stack(imgs,axis=-1)\n",
    "            # LOG TRANSFORM SPECTROGRAM\n",
    "            img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "            img = np.log(img)\n",
    "            \n",
    "            # STANDARDIZE PER IMAGE\n",
    "            img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2]\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3]\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1]\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,1]\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,1]\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,2]\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3]\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,3]\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,2]\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2]\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1]\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_raw(self,index):\n",
    "        if USE_PROCESSED and self.mode!='test':\n",
    "            X = np.zeros((2_000,8),dtype='float32')\n",
    "            y = np.zeros((6,),dtype='float32')\n",
    "            row = self.data.iloc[index]\n",
    "            X = self.raw_eegs[row.eeg_id]\n",
    "            y[:] = row[TARGETS]\n",
    "            return X,y\n",
    "        \n",
    "        X = np.zeros((10_000,8),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        eeg = self.raw_eegs[row.eeg_id]\n",
    "            \n",
    "        # FEATURE ENGINEER\n",
    "        X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n",
    "        X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n",
    "        X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n",
    "        X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n",
    "        X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        # STANDARDIZE\n",
    "        X = np.clip(X,-1024,1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "            \n",
    "        # BUTTER LOW-PASS FILTER\n",
    "        X = self.butter_lowpass_filter(X)\n",
    "        # Downsample\n",
    "        X = X[::5,:]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "                \n",
    "        return X,y\n",
    "        \n",
    "    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)\n",
    "        return filtered_data\n",
    "    \n",
    "    def resize(self, img,size):\n",
    "        composition = albu.Compose([\n",
    "                albu.Resize(size[0],size[1])\n",
    "            ])\n",
    "        return composition(image=img)['image']\n",
    "            \n",
    "    def augmentation(self, img):\n",
    "        composition = albu.Compose([\n",
    "                albu.HorizontalFlip(p=0.4)\n",
    "            ])\n",
    "        return composition(image=img)['image']\n",
    "\n",
    "def spectrogram_from_eeg(parquet_path):\n",
    "    \n",
    "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "    eeg = pd.read_parquet(parquet_path)\n",
    "    middle = (len(eeg)-10_000)//2\n",
    "    eeg = eeg.iloc[middle:middle+10_000]\n",
    "    \n",
    "    # VARIABLE TO HOLD SPECTROGRAM\n",
    "    img = np.zeros((100,300,4),dtype='float32')\n",
    "\n",
    "    for k in range(4):\n",
    "        COLS = FEATS[k]\n",
    "        \n",
    "        for kk in range(4):\n",
    "            # FILL NANS\n",
    "            x1 = eeg[COLS[kk]].values\n",
    "            x2 = eeg[COLS[kk+1]].values\n",
    "            m = np.nanmean(x1)\n",
    "            if np.isnan(x1).mean()<1: x1 = np.nan_to_num(x1,nan=m)\n",
    "            else: x1[:] = 0\n",
    "            m = np.nanmean(x2)\n",
    "            if np.isnan(x2).mean()<1: x2 = np.nan_to_num(x2,nan=m)\n",
    "            else: x2[:] = 0\n",
    "                \n",
    "            # COMPUTE PAIR DIFFERENCES\n",
    "            x = x1 - x2\n",
    "\n",
    "            # RAW SPECTROGRAM\n",
    "            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//300, \n",
    "                  n_fft=1024, n_mels=100, fmin=0, fmax=20, win_length=128)\n",
    "            \n",
    "            # LOG TRANSFORM\n",
    "            width = (mel_spec.shape[1]//30)*30\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "            img[:,:,k] += mel_spec_db\n",
    "                \n",
    "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "        img[:,:,k] /= 4.0\n",
    "          \n",
    "    return img\n",
    "\n",
    "def eeg_from_parquet(parquet_path):\n",
    "\n",
    "    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows-10_000)//2\n",
    "    eeg = eeg.iloc[offset:offset+10_000]\n",
    "    data = np.zeros((10_000,len(FEATS2)))\n",
    "    for j,col in enumerate(FEATS2):\n",
    "        \n",
    "        # FILL NAN\n",
    "        x = eeg[col].values.astype('float32')\n",
    "        m = np.nanmean(x)\n",
    "        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "        else: x[:] = 0\n",
    "        \n",
    "        data[:,j] = x\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21889bf1",
   "metadata": {
    "papermill": {
     "duration": 0.008568,
     "end_time": "2024-03-23T07:15:38.764739",
     "exception": false,
     "start_time": "2024-03-23T07:15:38.756171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DISPLAY DATA GENERATOR\n",
    "Below we display example data generator spectrogram images and raw EEG signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273a37e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:15:38.783292Z",
     "iopub.status.busy": "2024-03-23T07:15:38.783010Z",
     "iopub.status.idle": "2024-03-23T07:15:39.165832Z",
     "shell.execute_reply": "2024-03-23T07:15:39.164767Z"
    },
    "papermill": {
     "duration": 0.395159,
     "end_time": "2024-03-23T07:15:39.168543",
     "exception": false,
     "start_time": "2024-03-23T07:15:38.773384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SUBMISSION: \n",
    "    params = {'specs':spectrograms, 'eeg_specs':all_eegs, 'raw_eegs':all_raw_eegs}\n",
    "    gen = DataGenerator(train, augment=False, **params)\n",
    "    for x,y in gen:\n",
    "        break\n",
    "        \n",
    "    if DATA_TYPE in ['E','K','KE','K+E','K+E+KE','KR','ER','KER']:\n",
    "        x1 = x[0] if DATA_TYPE in ['KR','ER','KER'] else x\n",
    "        plt.imshow(x1[:,:,0])\n",
    "        plt.title(f'Target = {y.round(1)}',size=12)\n",
    "        plt.yticks([])\n",
    "        plt.ylabel('Frequencies (Hz)',size=12)\n",
    "        plt.xlabel('Time (sec)',size=12)\n",
    "    \n",
    "    if DATA_TYPE in ['R','KR','ER','KER']:\n",
    "        x1 = x[1] if DATA_TYPE in ['KR','ER','KER'] else x\n",
    "        plt.figure(figsize=(20,4))\n",
    "        offset = 0\n",
    "        for j in range(x1.shape[-1]):\n",
    "            if j!=0: offset -= x1[:,j].min()\n",
    "            plt.plot(range(2_000),x1[:,j]+offset,label=f'feature {j+1}')\n",
    "            offset += x1[:,j].max()\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a0d371",
   "metadata": {
    "papermill": {
     "duration": 0.010525,
     "end_time": "2024-03-23T07:15:39.189872",
     "exception": false,
     "start_time": "2024-03-23T07:15:39.179347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694954b9",
   "metadata": {
    "papermill": {
     "duration": 0.010388,
     "end_time": "2024-03-23T07:15:39.210987",
     "exception": false,
     "start_time": "2024-03-23T07:15:39.200599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f0913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:15:39.233328Z",
     "iopub.status.busy": "2024-03-23T07:15:39.232991Z",
     "iopub.status.idle": "2024-03-23T07:15:39.238787Z",
     "shell.execute_reply": "2024-03-23T07:15:39.238072Z"
    },
    "papermill": {
     "duration": 0.019297,
     "end_time": "2024-03-23T07:15:39.240613",
     "exception": false,
     "start_time": "2024-03-23T07:15:39.221316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if not SUBMISSION:\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        e3 = 1e-3 if DATA_TYPE in ['R'] else 1e-4\n",
    "        return [1e-3,1e-3,e3,1e-4,1e-5][epoch]\n",
    "\n",
    "    LR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "    \n",
    "    def lrfn2(epoch):\n",
    "        return [1e-5,1e-5,1e-6][epoch]\n",
    "\n",
    "    LR2 = tf.keras.callbacks.LearningRateScheduler(lrfn2, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6889613",
   "metadata": {
    "papermill": {
     "duration": 0.010126,
     "end_time": "2024-03-23T07:15:39.261356",
     "exception": false,
     "start_time": "2024-03-23T07:15:39.251230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL AND UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680fe5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:15:39.283839Z",
     "iopub.status.busy": "2024-03-23T07:15:39.283575Z",
     "iopub.status.idle": "2024-03-23T07:15:39.325406Z",
     "shell.execute_reply": "2024-03-23T07:15:39.324721Z"
    },
    "papermill": {
     "duration": 0.055478,
     "end_time": "2024-03-23T07:15:39.327269",
     "exception": false,
     "start_time": "2024-03-23T07:15:39.271791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate, LayerNormalization\n",
    "\n",
    "\n",
    "def build_model(data_type=DATA_TYPE):\n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        if data_type in ['R']:\n",
    "            model = build_wave_model()\n",
    "        elif data_type in ['K','E','KE','K+E','K+E+KE']:\n",
    "            model = build_spec_model()\n",
    "        elif data_type in ['KR','ER','KER']:\n",
    "            model = build_hybrid_model()\n",
    "    return model\n",
    "\n",
    "def build_spec_model(hybrid=False):  \n",
    "    inp = tf.keras.layers.Input((512,512,3))\n",
    "    base_model = load_model(f'{LOAD_BACKBONE_FROM}')    \n",
    "    x = base_model(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if not hybrid:\n",
    "        x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer=opt)  \n",
    "    return model\n",
    "\n",
    "def wave_block(x, filters, kernel_size, n):\n",
    "    dilation_rates = [2**i for i in range(n)]\n",
    "    x = Conv1D(filters = filters,\n",
    "               kernel_size = 1,\n",
    "               padding = 'same')(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same', \n",
    "                          activation = 'tanh', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        sigm_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same',\n",
    "                          activation = 'sigmoid', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        x = Multiply()([tanh_out, sigm_out])\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = Add()([res_x, x])\n",
    "    return res_x\n",
    "\n",
    "def build_wave_model(hybrid=False):\n",
    "        \n",
    "    # INPUT \n",
    "    inp = tf.keras.Input(shape=(2_000,8))\n",
    "    \n",
    "    ############\n",
    "    # FEATURE EXTRACTION SUB MODEL\n",
    "    inp2 = tf.keras.Input(shape=(2_000,1))\n",
    "    x = wave_block(inp2, 8, 4, 6)\n",
    "    x = wave_block(x, 16, 4, 6)\n",
    "    x = wave_block(x, 32, 4, 6)\n",
    "    x = wave_block(x, 64, 4, 6)\n",
    "    model2 = tf.keras.Model(inputs=inp2, outputs=x)\n",
    "    ###########\n",
    "    \n",
    "    # LEFT TEMPORAL CHAIN\n",
    "    x1 = model2(inp[:,:,0:1])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,1:2])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z1 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # LEFT PARASAGITTAL CHAIN\n",
    "    x1 = model2(inp[:,:,2:3])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,3:4])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z2 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # RIGHT PARASAGITTAL CHAIN\n",
    "    x1 = model2(inp[:,:,4:5])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,5:6])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z3 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # RIGHT TEMPORAL CHAIN\n",
    "    x1 = model2(inp[:,:,6:7])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,7:8])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z4 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # COMBINE CHAINS\n",
    "    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\n",
    "    if not hybrid:\n",
    "        y = tf.keras.layers.Dense(64, activation='relu')(y)\n",
    "        y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inp, outputs=y)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer = opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_hybrid_model():\n",
    "    model_spec = build_spec_model(True)\n",
    "    model_wave = build_wave_model(True)\n",
    "    inputs = [model_spec.input, model_wave.input]\n",
    "    x = [model_spec.output, model_wave.output]\n",
    "    x = tf.keras.layers.Concatenate()(x)\n",
    "    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer = opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    kl = tf.keras.metrics.KLDivergence()\n",
    "    return kl(y_true, y_pred)\n",
    "\n",
    "def plot_hist(hist):\n",
    "    metrics = ['loss']\n",
    "    for i,metric in enumerate(metrics):\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.plot(hist[metric])\n",
    "        plt.plot(hist[f'val_{metric}'])\n",
    "        plt.title(f'{metric}',size=12)\n",
    "        plt.ylabel(f'{metric}',size=12)\n",
    "        plt.xlabel('epoch',size=12)\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "        \n",
    "def dataset(data, mode='train', batch_size=8, data_type=DATA_TYPE, \n",
    "            augment=False, specs=None, eeg_specs=None, raw_eegs=None):\n",
    "    \n",
    "    BATCH_SIZE_PER_REPLICA = batch_size\n",
    "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "    gen = DataGenerator(data,mode=mode, data_type=data_type, augment=augment,\n",
    "                       specs=specs, eeg_specs=eeg_specs, raw_eegs=raw_eegs)\n",
    "    if data_type in ['K','E','KE','K+E','K+E+KE']: \n",
    "        inp = tf.TensorSpec(shape=(512,512,3), dtype=tf.float32)\n",
    "    elif data_type in ['KR','ER','KER']:\n",
    "        inp = (tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),tf.TensorSpec(shape=(2000,8), dtype=tf.float32))\n",
    "    elif data_type in ['R']:\n",
    "        inp = tf.TensorSpec(shape=(2000,8), dtype=tf.float32)\n",
    "        \n",
    "    output_signature = (inp,tf.TensorSpec(shape=(6,), dtype=tf.float32))\n",
    "    dataset = tf.data.Dataset.from_generator(generator=gen, output_signature=output_signature).batch(\n",
    "        BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "def reset_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "        \n",
    "def get_size(x):\n",
    "    if DATA_TYPE in ['K+E']:\n",
    "        size = 2*len(x)\n",
    "    elif  DATA_TYPE in ['K+E+KE']:\n",
    "        size = 3*len(x)\n",
    "    else:\n",
    "        size = len(x)\n",
    "    return size\n",
    "\n",
    "def predict(models, params, fold, models_path=None):\n",
    "    preds = []\n",
    "    if models_path is None: models_path = LOAD_MODELS_FROM\n",
    "    model_wave = build_wave_model()\n",
    "    model_spec = build_spec_model()\n",
    "    model_hybrid = build_hybrid_model()\n",
    "    for data_type in models:\n",
    "        data = params['data']\n",
    "        ver = models[data_type]\n",
    "        ds = dataset(data_type=data_type, **params)\n",
    "        if data_type in ['R']:\n",
    "            model = model_wave\n",
    "        elif data_type in ['K','E','KE','K+E','K+E+KE']:\n",
    "            model = model_spec\n",
    "        elif data_type in ['KR','ER','KER']:\n",
    "            model = model_hybrid\n",
    "        model.load_weights(f'{models_path}/model_{data_type}_{ver}_{fold}.weights.h5')\n",
    "        pred = model.predict(ds)\n",
    "        if data_type in ['K+E']:\n",
    "            pred = (pred[:len(data)] + pred[len(data):])/2\n",
    "        if data_type in ['K+E+KE']:\n",
    "            pred = (pred[:len(data)] + pred[len(data):len(data)*2] + pred[len(data)*2:])/3\n",
    "        preds.append(pred)\n",
    "    pred = np.mean(preds,axis=0)\n",
    "    del model_wave, model_spec, model_hybrid\n",
    "    gc.collect()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a14b4",
   "metadata": {
    "papermill": {
     "duration": 0.010343,
     "end_time": "2024-03-23T07:15:39.347988",
     "exception": false,
     "start_time": "2024-03-23T07:15:39.337645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf535fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "def init_logger(log_file: str = \"/kaggle/working/log/train.log\") -> getLogger:\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75dff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:15:39.370020Z",
     "iopub.status.busy": "2024-03-23T07:15:39.369699Z",
     "iopub.status.idle": "2024-03-23T07:15:39.382593Z",
     "shell.execute_reply": "2024-03-23T07:15:39.381751Z"
    },
    "papermill": {
     "duration": 0.026037,
     "end_time": "2024-03-23T07:15:39.384545",
     "exception": false,
     "start_time": "2024-03-23T07:15:39.358508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SUBMISSION and not TEST_ENSEMBLE:\n",
    "    reset_seed(42)\n",
    "    all_oof = []\n",
    "    all_true = []\n",
    "    val_sizes = []\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    total_hist = {}\n",
    "\n",
    "    exp_dir = os.path.join(\"/kaggle/working\", MODEL_DATA_TYPE)\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "    logger = init_logger(os.path.join(exp_dir, 'train.log'))\n",
    "\n",
    "    \n",
    "    # gkf = GroupKFold(n_splits=5)\n",
    "    # for fold, (train_index, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):\n",
    "    for fold in range(FOLD_NUM):\n",
    "        print('#'*25)\n",
    "        logger.info(f'### Fold {fold}')\n",
    "        valid_ids_path = f\"/kaggle/input/valid_eeg_ids_fold{fold}.yaml\"\n",
    "        with open(valid_ids_path, 'r') as file:\n",
    "            valid_ids = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        \n",
    "        params = {'specs':spectrograms, 'eeg_specs':all_eegs, 'raw_eegs':all_raw_eegs}\n",
    "        # data, val = train.iloc[train_index],train.iloc[valid_index]\n",
    "        data = train[~train.eeg_id.isin(valid_ids)]\n",
    "        val = train[train.eeg_id.isin(valid_ids)]\n",
    "        train_index = data.index\n",
    "        valid_index = val.index\n",
    "        train_dataset = dataset(data, **params)\n",
    "        val_dataset = dataset(val, mode='valid', **params)\n",
    "        # data = data[data['kl']<5.5]\n",
    "        train_dataset2 = dataset(data, **params)\n",
    "        train_size = get_size(train_index)\n",
    "        valid_size = get_size(valid_index)\n",
    "        logger.info(f'### train size {train_size}, valid size {valid_size}')\n",
    "        print('#'*25)\n",
    "        model = build_model()\n",
    "        hist = model.fit(train_dataset, validation_data = val_dataset, \n",
    "                         epochs=5, callbacks=[LR])\n",
    "        train_size = get_size(data)\n",
    "        logger.info(f'### seconds stage train size {train_size}, valid size {valid_size}')\n",
    "        print('#'*25)\n",
    "        hist2 = model.fit(train_dataset2, validation_data = val_dataset, \n",
    "                         epochs=3, callbacks=[LR2])\n",
    "        losses.append(hist.history['loss']+hist2.history['loss'])\n",
    "        val_losses.append(hist.history['val_loss']+hist2.history['val_loss'])\n",
    "        with strategy.scope():\n",
    "            model_dir = os.path.join(\"/kaggle/working\", MODEL_DATA_TYPE)\n",
    "            if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)\n",
    "            model_path = os.path.join(model_dir, f'model_{DATA_TYPE}_{MODEL[DATA_TYPE]}_{fold}.weights.h5')\n",
    "            model.save_weights(model_path)\n",
    "        params = {'mode':'valid','data':val,'specs':spectrograms, 'eeg_specs':all_eegs, 'raw_eegs':all_raw_eegs}\n",
    "        oof = predict(MODEL, params, fold, models_path=model_dir)\n",
    "        all_oof.append(oof)\n",
    "        all_true.append(train.iloc[valid_index][TARGETS].values)\n",
    "        val_sizes.append(len(valid_index))\n",
    "        del model, oof\n",
    "        gc.collect()\n",
    "        \n",
    "    total_hist['loss'] = np.mean(losses,axis=0)\n",
    "    total_hist['val_loss'] = np.mean(val_losses,axis=0)\n",
    "    all_oof = np.concatenate(all_oof)\n",
    "    all_true = np.concatenate(all_true)\n",
    "    plot_hist(total_hist)\n",
    "    logger.info(f'CV KL SCORE: {score(all_true,all_oof):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b966d",
   "metadata": {
    "papermill": {
     "duration": 0.010336,
     "end_time": "2024-03-23T07:15:39.405187",
     "exception": false,
     "start_time": "2024-03-23T07:15:39.394851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Local Ensemble Testing on CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41412a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T07:47:09.381815Z",
     "iopub.status.busy": "2024-03-23T07:47:09.380932Z",
     "iopub.status.idle": "2024-03-23T07:58:00.411960Z",
     "shell.execute_reply": "2024-03-23T07:58:00.410813Z"
    },
    "papermill": {
     "duration": 651.68033,
     "end_time": "2024-03-23T07:58:00.414106",
     "exception": false,
     "start_time": "2024-03-23T07:47:08.733776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "          MODEL_DATA_TYPE : 52, # 'LB':0.37 Kaggle's and EEG's spectrogram model version\n",
    "        }\n",
    "reset_seed(42)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "all_oof = []\n",
    "all_true = []\n",
    "oof_df = train[[\"eeg_id\"] + TARGETS].copy()\n",
    "pred_cols = [f\"pred_{c}\" for c in TARGETS]\n",
    "oof_df[pred_cols] = 0\n",
    "\n",
    "logger.info(\"oof scoring\")\n",
    "# for i, (_, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):   \n",
    "#     print(f'Fold {i+1}')\n",
    "#     val_data = train.iloc[valid_index].copy()\n",
    "for fold in range(FOLD_NUM):\n",
    "    print('#'*25)\n",
    "    print(f'### Fold {fold+1}')\n",
    "    valid_ids_path = f\"/kaggle/input/valid_eeg_ids_fold{fold}.yaml\"\n",
    "    with open(valid_ids_path, 'r') as file:\n",
    "        valid_ids = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    val_data = train[train.eeg_id.isin(valid_ids)]\n",
    "    valid_index = val.index\n",
    "    params = {'specs':spectrograms, 'eeg_specs':all_eegs, 'raw_eegs':all_raw_eegs}\n",
    "    data, val = train.iloc[train_index],train.iloc[valid_index]\n",
    "    logger.info(f'valid size {len(val)}')\n",
    "    params = {'mode':'valid','data':val_data,'specs':spectrograms, 'eeg_specs':all_eegs, 'raw_eegs':all_raw_eegs}\n",
    "    model_dir = os.path.join(\"/kaggle/working\", MODEL_DATA_TYPE)\n",
    "    oof = predict(MODELS, params, fold, model_dir)\n",
    "    all_oof.append(oof)\n",
    "    all_true.append(val_data[TARGETS].values)\n",
    "    oof_df.loc[val_data.index, pred_cols] = oof\n",
    "    logger.info(f'Fold {fold+1} KL SCORE: {score(val_data[TARGETS].values, oof):.4f}')\n",
    "\n",
    "all_oof = np.concatenate(all_oof)\n",
    "all_true = np.concatenate(all_true)\n",
    "logger.info(f'CV KL SCORE: {score(all_true,all_oof):.4f}')\n",
    "oof_df.to_csv(os.path.join(model_dir, \"oof.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a313e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332fb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297782,
     "sourceId": 7392775,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4407194,
     "sourceId": 7570342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4382744,
     "sourceId": 7752462,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4550181,
     "sourceId": 7776446,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4417235,
     "sourceId": 7818976,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2770.31283,
   "end_time": "2024-03-23T07:58:19.988389",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-23T07:12:09.675559",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
