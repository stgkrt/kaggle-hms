{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019fdd01",
   "metadata": {
    "papermill": {
     "duration": 0.004039,
     "end_time": "2024-01-27T23:30:19.904365",
     "exception": false,
     "start_time": "2024-01-27T23:30:19.900326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e3ba5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T23:30:19.912750Z",
     "iopub.status.busy": "2024-01-27T23:30:19.912394Z",
     "iopub.status.idle": "2024-01-27T23:30:26.256827Z",
     "shell.execute_reply": "2024-01-27T23:30:26.255790Z"
    },
    "papermill": {
     "duration": 6.351221,
     "end_time": "2024-01-27T23:30:26.259091",
     "exception": false,
     "start_time": "2024-01-27T23:30:19.907870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing essential libraries\n",
    "import gc\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# torchvision for image processing and augmentation\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Suppressing minor warnings to keep the output clean\n",
    "warnings.filterwarnings('ignore', category=Warning)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded89c0",
   "metadata": {
    "papermill": {
     "duration": 0.003564,
     "end_time": "2024-01-27T23:30:26.266541",
     "exception": false,
     "start_time": "2024-01-27T23:30:26.262977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5155d55b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T23:30:26.275064Z",
     "iopub.status.busy": "2024-01-27T23:30:26.274674Z",
     "iopub.status.idle": "2024-01-27T23:30:26.452107Z",
     "shell.execute_reply": "2024-01-27T23:30:26.451036Z"
    },
    "papermill": {
     "duration": 0.18406,
     "end_time": "2024-01-27T23:30:26.454209",
     "exception": false,
     "start_time": "2024-01-27T23:30:26.270149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration class containing hyperparameters and settings\n",
    "class Config:\n",
    "    model_name = \"resnet34d\"\n",
    "    seed = 42 \n",
    "    image_transform = transforms.Resize((512,512))  \n",
    "    batch_size = 16\n",
    "    num_epochs = 9\n",
    "    num_folds = 5\n",
    "\n",
    "Config.exp_name = \"open\" + \"_\" + Config.model_name\n",
    "# Set the seed for reproducibility across multiple libraries\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(Config.seed)\n",
    "\n",
    "# Define the 'Kullback Leibler Divergence' loss function\n",
    "def KL_loss(p,q):\n",
    "    epsilon=10**(-15)\n",
    "    p=torch.clip(p,epsilon,1-epsilon)\n",
    "    q = nn.functional.log_softmax(q,dim=1)\n",
    "    return torch.mean(torch.sum(p*(torch.log(p)-q),dim=1))\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28dc538",
   "metadata": {
    "papermill": {
     "duration": 0.003768,
     "end_time": "2024-01-27T23:30:26.462131",
     "exception": false,
     "start_time": "2024-01-27T23:30:26.458363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b07548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T23:30:26.471278Z",
     "iopub.status.busy": "2024-01-27T23:30:26.470877Z",
     "iopub.status.idle": "2024-01-27T23:30:26.974372Z",
     "shell.execute_reply": "2024-01-27T23:30:26.973429Z"
    },
    "papermill": {
     "duration": 0.510665,
     "end_time": "2024-01-27T23:30:26.976548",
     "exception": false,
     "start_time": "2024-01-27T23:30:26.465883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\")\n",
    "\n",
    "# Define labels for classification\n",
    "labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
    "\n",
    "# Initialize an empty DataFrame for storing features\n",
    "train_feats = pd.DataFrame()\n",
    "\n",
    "# Aggregate votes for each label and merge into train_feats DataFrame\n",
    "for label in labels:\n",
    "    # Group by 'spectrogram_id' and sum the votes for the current label\n",
    "    group = train_df[f'{label}_vote'].groupby(train_df['spectrogram_id']).sum()\n",
    "\n",
    "    # Create a DataFrame from the grouped data\n",
    "    label_vote_sum = pd.DataFrame({'spectrogram_id': group.index, f'{label}_vote_sum': group.values})\n",
    "\n",
    "    # Initialize train_feats with the first label or merge subsequent labels\n",
    "    if label == 'seizure':\n",
    "        train_feats = label_vote_sum\n",
    "    else:\n",
    "        train_feats = train_feats.merge(label_vote_sum, on='spectrogram_id', how='left')\n",
    "\n",
    "# Add a column to sum all votes\n",
    "train_feats['total_vote'] = 0\n",
    "for label in labels:\n",
    "    train_feats['total_vote'] += train_feats[f'{label}_vote_sum']\n",
    "\n",
    "# Calculate and store the normalized vote for each label\n",
    "for label in labels:\n",
    "    train_feats[f'{label}_vote'] = train_feats[f'{label}_vote_sum'] / train_feats['total_vote']\n",
    "\n",
    "# Select relevant columns for the training features\n",
    "choose_cols = ['spectrogram_id']\n",
    "for label in labels:\n",
    "    choose_cols += [f'{label}_vote']\n",
    "train_feats = train_feats[choose_cols]\n",
    "\n",
    "# Add a column with the path to the spectrogram files\n",
    "train_feats['path'] = train_feats['spectrogram_id'].apply(lambda x: \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\" + str(x) + \".parquet\")\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e1999",
   "metadata": {
    "papermill": {
     "duration": 0.004019,
     "end_time": "2024-01-27T23:30:26.984729",
     "exception": false,
     "start_time": "2024-01-27T23:30:26.980710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ea88bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T23:30:26.994774Z",
     "iopub.status.busy": "2024-01-27T23:30:26.993791Z",
     "iopub.status.idle": "2024-01-27T23:30:27.003116Z",
     "shell.execute_reply": "2024-01-27T23:30:27.002262Z"
    },
    "papermill": {
     "duration": 0.016573,
     "end_time": "2024-01-27T23:30:27.005321",
     "exception": false,
     "start_time": "2024-01-27T23:30:26.988748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_batch(paths, batch_size=Config.batch_size):\n",
    "    # Set a small epsilon to avoid division by zero\n",
    "    eps = 1e-6\n",
    "\n",
    "    # Initialize a list to store batch data\n",
    "    batch_data = []\n",
    "\n",
    "    # Iterate over each path in the provided paths\n",
    "    for path in paths:\n",
    "        # Read data from parquet file\n",
    "        data = pd.read_parquet(path[0])\n",
    "\n",
    "        # Fill missing values, remove time column, and transpose\n",
    "        data = data.fillna(-1).values[:, 1:].T\n",
    "\n",
    "        # Clip values and apply logarithmic transformation\n",
    "        data = np.clip(data, np.exp(-6), np.exp(10))\n",
    "        data = np.log(data)\n",
    "\n",
    "        # Normalize the data\n",
    "        data_mean = data.mean(axis=(0, 1))\n",
    "        data_std = data.std(axis=(0, 1))\n",
    "        data = (data - data_mean) / (data_std + eps)\n",
    "\n",
    "        # Convert data to a PyTorch tensor and apply transformations\n",
    "        data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
    "        data = Config.image_transform(data_tensor)\n",
    "\n",
    "        # Append the processed data to the batch_data list\n",
    "        batch_data.append(data)\n",
    "\n",
    "    # Stack all the batch data into a single tensor\n",
    "    batch_data = torch.stack(batch_data)\n",
    "\n",
    "    # Return the batch data\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d1a72",
   "metadata": {
    "papermill": {
     "duration": 0.003784,
     "end_time": "2024-01-27T23:30:27.013177",
     "exception": false,
     "start_time": "2024-01-27T23:30:27.009393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1563ef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T23:30:27.022910Z",
     "iopub.status.busy": "2024-01-27T23:30:27.022192Z",
     "iopub.status.idle": "2024-01-28T05:41:36.730745Z",
     "shell.execute_reply": "2024-01-28T05:41:36.729781Z"
    },
    "papermill": {
     "duration": 22269.726932,
     "end_time": "2024-01-28T05:41:36.744025",
     "exception": false,
     "start_time": "2024-01-27T23:30:27.017093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting training for fold 1\n",
      "Epoch 1: Train Loss = 0.87\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/util.py:76\u001b[0m, in \u001b[0;36m_is_path_like\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_path_like\u001b[39m(path):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__fspath__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stringify_path\u001b[39m(path):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pyarrow._dataset._make_file_source'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/pyarrow/util.py\", line 76, in _is_path_like\n",
      "    def _is_path_like(path):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Called Open() on an uninitialized FileSource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m test_idx1 \u001b[38;5;241m=\u001b[39m test_idx[idx:idx \u001b[38;5;241m+\u001b[39m Config\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m     75\u001b[0m test_X1_path \u001b[38;5;241m=\u001b[39m train_feats[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39miloc[test_idx1]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m---> 76\u001b[0m test_X1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X1_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m test_y1 \u001b[38;5;241m=\u001b[39m train_feats[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseizure_vote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlpd_vote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpd_vote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlrda_vote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrda_vote\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother_vote\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39miloc[test_idx1]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     78\u001b[0m labels\u001b[38;5;241m.\u001b[39mextend(test_y1\u001b[38;5;241m.\u001b[39mtolist())\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(paths, batch_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Iterate over each path in the provided paths\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Read data from parquet file\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Fill missing values, remove time column, and transpose\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:670\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    668\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:272\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    266\u001b[0m     path,\n\u001b[1;32m    267\u001b[0m     filesystem,\n\u001b[1;32m    268\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    269\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    270\u001b[0m )\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/parquet/core.py:2926\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword is no longer supported with the new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2921\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets-based implementation. Specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2922\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to temporarily recover the old \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2923\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehaviour.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2924\u001b[0m     )\n\u001b[1;32m   2925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2926\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43m_ParquetDatasetV2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2927\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2940\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2941\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   2942\u001b[0m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[1;32m   2943\u001b[0m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[1;32m   2944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/parquet/core.py:2466\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2463\u001b[0m     fragment \u001b[38;5;241m=\u001b[39m parquet_format\u001b[38;5;241m.\u001b[39mmake_fragment(single_file, filesystem)\n\u001b[1;32m   2465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mFileSystemDataset(\n\u001b[0;32m-> 2466\u001b[0m         [fragment], schema\u001b[38;5;241m=\u001b[39mschema \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfragment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphysical_schema\u001b[49m,\n\u001b[1;32m   2467\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mparquet_format,\n\u001b[1;32m   2468\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfragment\u001b[38;5;241m.\u001b[39mfilesystem\n\u001b[1;32m   2469\u001b[0m     )\n\u001b[1;32m   2470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2472\u001b[0m \u001b[38;5;66;03m# check partitioning to enable dictionary encoding\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/_dataset.pyx:1004\u001b[0m, in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Called Open() on an uninitialized FileSource"
     ]
    }
   ],
   "source": [
    "# Determine device availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Assuming train_feats is defined and contains the training features and labels\n",
    "total_idx = np.arange(len(train_feats))\n",
    "np.random.shuffle(total_idx)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "oof_df = pd.DataFrame()\n",
    "# Cross-validation loop\n",
    "for fold in range(Config.num_folds):\n",
    "    # Split data into train and test sets for this fold\n",
    "    # yaml file with\n",
    "    valid_ids_path = f\"/kaggle/input/valid_spec_ids_fold{fold}.yaml\"\n",
    "    with open(valid_ids_path, 'r') as file:\n",
    "        valid_ids = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    # test_idx = total_idx[fold * len(total_idx) // Config.num_folds:(fold + 1) * len(total_idx) // Config.num_folds]\n",
    "    test_idx = train_feats[train_feats['spectrogram_id'].isin(valid_ids)].index\n",
    "    train_idx = np.array([idx for idx in total_idx if idx not in test_idx])\n",
    "\n",
    "\n",
    "    # Initialize ResNet34d model with pretrained weights\n",
    "    model = timm.create_model(Config.model_name, pretrained=True, num_classes=6, in_chans=1)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, betas=(0.5, 0.999), weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=Config.num_epochs)\n",
    "\n",
    "    best_test_loss = float('inf')\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    print(f\"Starting training for fold {fold + 1}\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(Config.num_epochs):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        random_num = np.arange(len(train_idx))\n",
    "        np.random.shuffle(random_num)\n",
    "        train_idx = train_idx[random_num]\n",
    "\n",
    "        # Iterate over batches in the training set\n",
    "        for idx in range(0, len(train_idx), Config.batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            train_idx1 = train_idx[idx:idx + Config.batch_size]\n",
    "            train_X1_path = train_feats[['path']].iloc[train_idx1].values\n",
    "            train_X1 = get_batch(train_X1_path, batch_size=Config.batch_size)\n",
    "            train_y1 = train_feats[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].iloc[train_idx1].values\n",
    "            train_y1 = torch.Tensor(train_y1)\n",
    "\n",
    "            train_pred = model(train_X1.to(device))\n",
    "            loss = KL_loss(train_y1.to(device), train_pred)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        epoch_train_loss = np.mean(train_loss)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {epoch_train_loss:.2f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Evaluation loop\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        valid_spec_ids = train_feats['spectrogram_id'].iloc[test_idx].values.tolist()\n",
    "        with torch.no_grad():\n",
    "            for idx in range(0, len(test_idx), Config.batch_size):\n",
    "                test_idx1 = test_idx[idx:idx + Config.batch_size]\n",
    "                test_X1_path = train_feats[['path']].iloc[test_idx1].values\n",
    "                test_X1 = get_batch(test_X1_path, batch_size=Config.batch_size)\n",
    "                test_y1 = train_feats[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].iloc[test_idx1].values\n",
    "                labels.extend(test_y1.tolist())\n",
    "                test_y1 = torch.Tensor(test_y1)\n",
    "\n",
    "                test_pred = model(test_X1.to(device))\n",
    "                loss = KL_loss(test_y1.to(device), test_pred)\n",
    "                test_loss.append(loss.item())\n",
    "                predictions.extend(test_pred.cpu().numpy().tolist())\n",
    "\n",
    "        epoch_test_loss = np.mean(test_loss)\n",
    "        test_losses.append(epoch_test_loss)\n",
    "        print(f\"Epoch {epoch + 1}: Test Loss = {epoch_test_loss:.2f}\")\n",
    "\n",
    "        # Save the model if it has the best test loss so far\n",
    "        if epoch_test_loss < best_test_loss:\n",
    "            best_test_loss = epoch_test_loss\n",
    "            model_dir = os.path.join(\"/kaggle/working\", Config.exp_name)\n",
    "            if not os.path.exists(model_dir):\n",
    "                os.makedirs(model_dir)\n",
    "            model_name = Config.model_name\n",
    "            model_path = os.path.join(model_dir, f\"{model_name}_fold{fold}.pth\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            oof_df_ = pd.DataFrame({\n",
    "                'spectrogram_id': valid_spec_ids,\n",
    "            })\n",
    "            vote_cols = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "            oof_df_ = pd.concat([oof_df_, pd.DataFrame(labels, columns=['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote'])], axis=1)\n",
    "            pred_cols = [\"pred_\" + col for col in vote_cols]\n",
    "            oof_df_ = pd.concat([oof_df_, pd.DataFrame(predictions, columns=pred_cols)], axis=1)\n",
    "            oof_df_.to_csv(os.path.join(model_dir, f\"oof_fold{fold}.csv\"), index=False)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"Fold {fold + 1} Best Test Loss: {best_test_loss:.2f}\")\n",
    "    oof_df = pd.concat([oof_df, oof_df_], axis=0)\n",
    "    oof_df.to_csv(os.path.join(model_dir, \"oof.csv\"), index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac2148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22282.849875,
   "end_time": "2024-01-28T05:41:39.086189",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-27T23:30:16.236314",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "057dd5f0bfbb4751b26dd865b2f43498": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c7aeb89d3f0e44b5b60a1f54656b03fc",
       "placeholder": "​",
       "style": "IPY_MODEL_0f2d6af0647c4abb8fe1e8bd7718dfbd",
       "value": " 87.4M/87.4M [00:00&lt;00:00, 197MB/s]"
      }
     },
     "0f2d6af0647c4abb8fe1e8bd7718dfbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6a9b4b1ef2494fe99d3fbcca98f0ae5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc58ca00311949af93491420767b2ebf",
       "max": 87356926,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_850fae731ca347fc8a4d9b0420230165",
       "value": 87356926
      }
     },
     "6d37aff4c7404f009ed8006cdcd7ff58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f7e86e984e34d9ba27254d99c836b96",
       "placeholder": "​",
       "style": "IPY_MODEL_ebc0d57645bb40588191c11976ac64d7",
       "value": "model.safetensors: 100%"
      }
     },
     "850fae731ca347fc8a4d9b0420230165": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8f7e86e984e34d9ba27254d99c836b96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba35aaf208d6471fb7cf496a01dc7fa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6d37aff4c7404f009ed8006cdcd7ff58",
        "IPY_MODEL_6a9b4b1ef2494fe99d3fbcca98f0ae5a",
        "IPY_MODEL_057dd5f0bfbb4751b26dd865b2f43498"
       ],
       "layout": "IPY_MODEL_fc1b1035c5fa4230a635e9b46c06f7ae"
      }
     },
     "c7aeb89d3f0e44b5b60a1f54656b03fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc58ca00311949af93491420767b2ebf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebc0d57645bb40588191c11976ac64d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fc1b1035c5fa4230a635e9b46c06f7ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
