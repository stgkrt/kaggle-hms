{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3d5189",
   "metadata": {
    "papermill": {
     "duration": 0.011436,
     "end_time": "2024-02-20T13:39:08.402690",
     "exception": false,
     "start_time": "2024-02-20T13:39:08.391254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About this notebook\n",
    "\n",
    "This is a modifyed version of this amazing [notebook](https://www.kaggle.com/code/nischaydnk/hms-submission-1d-eegnet-pipeline-lightning) shared by @nischaydnk.\n",
    "\n",
    "As stated [here](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477498), adding ` 0.166666667` to the targets will reduce the CV/LB gap.\n",
    "\n",
    "I also used the data preprocessing from this [notebook](https://www.kaggle.com/code/alejopaullier/hms-wavenet-pytorch-train/notebook).\n",
    "\n",
    "Changing the optimizer to [Adan](https://github.com/lucidrains/Adan-pytorch) improved the CV score.\n",
    "\n",
    "This model only uses only 8 channels from raw EEG signals as shared by [Chris Deotte](https://www.kaggle.com/code/cdeotte/how-to-make-spectrogram-from-eeg/notebook).\n",
    "I'll do a lot of experimentation in this notebook, change the archtecture of the model, add crossentropy loss and play with data to see if their improve our score.\n",
    "\n",
    "**If you find this notebook usefull please upvote and stay tuned**\n",
    "\n",
    "## Version1\n",
    "* `CV=0.5162483866506282` `LB=0.48`\n",
    "### Hyperparams\n",
    "```\n",
    "\n",
    "   scheduler='CosineAnnealingWarmRestarts' \n",
    "   # CosineAnnealingWarmRestarts params\n",
    "    cosanneal_res_params={\n",
    "        'T_0':20,\n",
    "        'eta_min':1e-6,\n",
    "        'T_mult':1,\n",
    "        'last_epoch':-1}\n",
    "    print_freq=50\n",
    "    num_workers = 1\n",
    "    model_name = 'resnet501d_lstm'\n",
    "    optimizer='Adam'\n",
    "    epochs = 20\n",
    "    eps = 1e-6\n",
    "    lr = 8e-3\n",
    "    min_lr = 1e-6\n",
    "    in_channels = 1\n",
    "    batch_size = 64\n",
    "    weight_decay = 1e-3\n",
    "    seed = 2024\n",
    "```\n",
    "## Version 2 \n",
    "### Hyperparams\n",
    "```\n",
    "\n",
    "   scheduler='CosineAnnealingWarmRestarts' \n",
    "   # CosineAnnealingWarmRestarts params\n",
    "    cosanneal_res_params={\n",
    "        'T_0':20,\n",
    "        'eta_min':1e-6,\n",
    "        'T_mult':1,\n",
    "        'last_epoch':-1}\n",
    "    print_freq=50\n",
    "    num_workers = 1\n",
    "    model_name = 'resnet501d_lstm'\n",
    "    optimizer='Adam'\n",
    "    epochs = 20\n",
    "    eps = 1e-6\n",
    "    lr = 8e-3\n",
    "    min_lr = 1e-6\n",
    "    in_channels = 1\n",
    "    batch_size = 32\n",
    "    weight_decay = 1e-2\n",
    "    max_grad_norm = 1e7\n",
    "    seed = 2024\n",
    "```\n",
    "* In this version, the model evaluate the montages separtely like this [notebook](https://www.kaggle.com/code/alejopaullier/hms-wavenet-pytorch-train).\n",
    "* `CV=0.5162483866506282` `LB=0.55`\n",
    "\n",
    "\n",
    "## Version 3\n",
    "* Added sequence pooling for the rrnn output\n",
    "\n",
    "The Sequence Pooling Layer is used instead of a [CLASS] token in CCTs. This layer introduces a learnable weight which allows the model to perform a weighted average over all the sequences instead of taking output from one special [CLASS] token or from simple average across all the sequences.\n",
    "Taken from this [notebook](https://www.kaggle.com/code/utsavnandi/compact-convolutional-transformer-using-pytorch).\n",
    "```\n",
    "class SeqPool(nn.Module):\n",
    "    def __init__(self, emb_dim=192):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(emb_dim, 1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, seq_len, emb_dim = x.shape\n",
    "        identity = x\n",
    "        x = self.dense(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.softmax(x)\n",
    "        x = x @ identity\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        return x\n",
    "```\n",
    "### Hyperparams\n",
    "```\n",
    "\n",
    "   scheduler='CosineAnnealingWarmRestarts' \n",
    "   # CosineAnnealingWarmRestarts params\n",
    "    cosanneal_res_params={\n",
    "        'T_0':20,\n",
    "        'eta_min':1e-6,\n",
    "        'T_mult':1,\n",
    "        'last_epoch':-1}\n",
    "    print_freq=50\n",
    "    num_workers = 1\n",
    "    model_name = 'resnet501d_lstm'\n",
    "    optimizer='Adan'\n",
    "    epochs = 20\n",
    "    eps = 1e-6\n",
    "    lr = 8e-3\n",
    "    min_lr = 1e-6\n",
    "    in_channels = 8\n",
    "    batch_size = 64\n",
    "    weight_decay = 1e-2\n",
    "    max_grad_norm = 1e7\n",
    "    seed = 2024\n",
    "```\n",
    "\n",
    "## Version 4\n",
    "\n",
    "I divided my data set into two population and trained a two stage model from version1. I took the idea from this [notebook](https://www.kaggle.com/code/seanbearden/effnetb0-2-pop-model-train-twice-lb-0-39/notebook).\n",
    "\n",
    "### Hyperparams\n",
    "\n",
    "```\n",
    "\n",
    "   scheduler='CosineAnnealingWarmRestarts' \n",
    "   # CosineAnnealingWarmRestarts params\n",
    "    cosanneal_res_params={\n",
    "        'T_0':20,\n",
    "        'eta_min':1e-6,\n",
    "        'T_mult':1,\n",
    "        'last_epoch':-1}\n",
    "    print_freq=50\n",
    "    num_workers = 1\n",
    "    model_name = 'resnet501d_lstm'\n",
    "    optimizer='Adan'\n",
    "    epochs = 20\n",
    "    eps = 1e-6\n",
    "    lr = 8e-3\n",
    "    min_lr = 1e-6\n",
    "    in_channels = 8\n",
    "    batch_size = 64\n",
    "    weight_decay = 1e-2\n",
    "    max_grad_norm = 1e7\n",
    "    seed = 2024\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82468a10",
   "metadata": {
    "papermill": {
     "duration": 0.010594,
     "end_time": "2024-02-20T13:39:08.424415",
     "exception": false,
     "start_time": "2024-02-20T13:39:08.413821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f638a845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:39:08.448319Z",
     "iopub.status.busy": "2024-02-20T13:39:08.447724Z",
     "iopub.status.idle": "2024-02-20T13:39:08.460149Z",
     "shell.execute_reply": "2024-02-20T13:39:08.459271Z"
    },
    "papermill": {
     "duration": 0.027101,
     "end_time": "2024-02-20T13:39:08.462258",
     "exception": false,
     "start_time": "2024-02-20T13:39:08.435157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# directory settings\n",
    "# ====================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# OUTPUT_DIR = './'\n",
    "# if not os.path.exists(OUTPUT_DIR):\n",
    "#     os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "OUTPUT_DIR = \"/kaggle/working/Resnet1d_GRU_torch\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "POP_2_DIR = os.path.join(OUTPUT_DIR, 'stage2')\n",
    "if not os.path.exists(POP_2_DIR):\n",
    "    os.makedirs(POP_2_DIR)\n",
    "    \n",
    "POP_1_DIR = os.path.join(OUTPUT_DIR, 'stage1')\n",
    "if not os.path.exists(POP_1_DIR):\n",
    "    os.makedirs(POP_1_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9308238",
   "metadata": {
    "papermill": {
     "duration": 0.010616,
     "end_time": "2024-02-20T13:39:08.483737",
     "exception": false,
     "start_time": "2024-02-20T13:39:08.473121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a1ec1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:39:08.506622Z",
     "iopub.status.busy": "2024-02-20T13:39:08.506265Z",
     "iopub.status.idle": "2024-02-20T13:39:22.390307Z",
     "shell.execute_reply": "2024-02-20T13:39:22.389312Z"
    },
    "papermill": {
     "duration": 13.898864,
     "end_time": "2024-02-20T13:39:22.393405",
     "exception": false,
     "start_time": "2024-02-20T13:39:08.494541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "# sys.path.append('/kaggle/input/kaggle-kl-div')\n",
    "# from kaggle_kl_div import score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations import (Compose, Normalize, Resize, RandomResizedCrop, HorizontalFlip, VerticalFlip, ShiftScaleRotate, Transpose)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "VERSION=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9c04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5edeb32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:39:22.422000Z",
     "iopub.status.busy": "2024-02-20T13:39:22.421506Z",
     "iopub.status.idle": "2024-02-20T13:39:22.433686Z",
     "shell.execute_reply": "2024-02-20T13:39:22.432464Z"
    },
    "papermill": {
     "duration": 0.029582,
     "end_time": "2024-02-20T13:39:22.435956",
     "exception": false,
     "start_time": "2024-02-20T13:39:22.406374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "\n",
    "class CFG:\n",
    "    wandb = False\n",
    "    debug = False\n",
    "    train=True\n",
    "    apex=True\n",
    "    visualize=True\n",
    "    stage1_pop1=True\n",
    "    stage2_pop2=False\n",
    "    scheduler='CosineAnnealingWarmRestarts' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts','OneCycleLR']\n",
    "    # CosineAnnealingLR params\n",
    "    cosanneal_params={\n",
    "        'T_max':6,\n",
    "        'eta_min':1e-5,\n",
    "        'last_epoch':-1\n",
    "    }\n",
    "    #ReduceLROnPlateau params\n",
    "    reduce_params={\n",
    "        'mode':'min',\n",
    "        'factor':0.2,\n",
    "        'patience':4,\n",
    "        'eps':1e-6,\n",
    "        'verbose':True\n",
    "    }\n",
    "    # CosineAnnealingWarmRestarts params\n",
    "    cosanneal_res_params={\n",
    "        'T_0':20,\n",
    "        'eta_min':1e-6,\n",
    "        'T_mult':1,\n",
    "        'last_epoch':-1\n",
    "    }\n",
    "    print_freq=50\n",
    "    num_workers = 1\n",
    "    model_name = 'resnet1d_gru'\n",
    "    optimizer='Adan'\n",
    "    epochs = 10\n",
    "    factor = 0.9\n",
    "    patience = 2\n",
    "    eps = 1e-6\n",
    "    lr = 8e-3\n",
    "    min_lr = 1e-6\n",
    "    in_channels = 8\n",
    "    batch_size = 64\n",
    "    weight_decay = 1e-2\n",
    "    batch_scheduler = True\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1e7\n",
    "    seed = 2024\n",
    "    target_cols = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    target_size = 6\n",
    "    pred_cols = ['pred_seizure_vote', 'pred_lpd_vote', 'pred_gpd_vote', 'pred_lrda_vote', 'pred_grda_vote', 'pred_other_vote']\n",
    "    n_fold = 5\n",
    "    trn_fold = [0, 1, 2, 3, 4]\n",
    "    PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'\n",
    "    data_root = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"\n",
    "    raw_eeg_path = \"/kaggle/input/brain-eegs/eegs.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c35f0",
   "metadata": {
    "papermill": {
     "duration": 0.012027,
     "end_time": "2024-02-20T13:39:22.461399",
     "exception": false,
     "start_time": "2024-02-20T13:39:22.449372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda1fa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:39:22.487641Z",
     "iopub.status.busy": "2024-02-20T13:39:22.487254Z",
     "iopub.status.idle": "2024-02-20T13:39:22.516856Z",
     "shell.execute_reply": "2024-02-20T13:39:22.516021Z"
    },
    "papermill": {
     "duration": 0.045586,
     "end_time": "2024-02-20T13:39:22.519244",
     "exception": false,
     "start_time": "2024-02-20T13:39:22.473658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "def get_score(preds, targets):\n",
    "    oof = pd.DataFrame(preds.copy())\n",
    "    oof['id'] = np.arange(len(oof))\n",
    "\n",
    "    true = pd.DataFrame(targets.copy())\n",
    "    true['id'] = np.arange(len(true))\n",
    "\n",
    "    cv = score(solution=true, submission=oof, row_id_column_name='id')\n",
    "    return cv\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def denoise_filter(x):\n",
    "    # Sample rate and desired cutoff frequencies (in Hz).\n",
    "    fs = 200.0\n",
    "    lowcut = 1.0\n",
    "    highcut = 25.0\n",
    "    \n",
    "    # Filter a noisy signal.\n",
    "    T = 50\n",
    "    nsamples = T * fs\n",
    "    t = np.arange(0, nsamples) / fs\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)\n",
    "    y = (y + np.roll(y,-1)+ np.roll(y,-2)+ np.roll(y,-3))/4\n",
    "    y = y[0:-1:4]\n",
    "    \n",
    "    return y\n",
    "\n",
    "class KLDivLossWithLogits(nn.KLDivLoss):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        y = nn.functional.log_softmax(y,  dim=1)\n",
    "        loss = super().forward(y, t)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "target_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n",
    "label_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\n",
    "num_to_label = {v: k for k, v in label_to_num.items()}    \n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2a5bf",
   "metadata": {
    "papermill": {
     "duration": 0.011952,
     "end_time": "2024-02-20T13:39:22.543825",
     "exception": false,
     "start_time": "2024-02-20T13:39:22.531873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78edd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:39:22.569793Z",
     "iopub.status.busy": "2024-02-20T13:39:22.569504Z",
     "iopub.status.idle": "2024-02-20T13:39:23.602056Z",
     "shell.execute_reply": "2024-02-20T13:39:23.601080Z"
    },
    "papermill": {
     "duration": 1.048113,
     "end_time": "2024-02-20T13:39:23.604213",
     "exception": false,
     "start_time": "2024-02-20T13:39:22.556100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train_3to20.csv')\n",
    "TARGETS = train.columns[-6:]\n",
    "print('Train shape:', train.shape )\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "train['total_evaluators'] = train[['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']].sum(axis=1)\n",
    "\n",
    "train_uniq = train.drop_duplicates(subset=['eeg_id'] + list(TARGETS))\n",
    "\n",
    "print(f'There are {train.patient_id.nunique()} patients in the training data.')\n",
    "print(f'There are {train.eeg_id.nunique()} EEG IDs in the training data.')\n",
    "print(f'There are {train_uniq.shape[0]} unique eeg_id + votes in the training data.')\n",
    "\n",
    "train_uniq.eeg_id.value_counts().value_counts().plot(kind='bar', title=f'Distribution of Count of EEG w Unique Vote: '\n",
    "                                                                    f'{train_uniq.shape[0]} examples');\n",
    "\n",
    "del train_uniq\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780f5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:39:23.630189Z",
     "iopub.status.busy": "2024-02-20T13:39:23.629845Z",
     "iopub.status.idle": "2024-02-20T13:39:23.959359Z",
     "shell.execute_reply": "2024-02-20T13:39:23.958410Z"
    },
    "papermill": {
     "duration": 0.345275,
     "end_time": "2024-02-20T13:39:23.961779",
     "exception": false,
     "start_time": "2024-02-20T13:39:23.616504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Total Evaluators')\n",
    "plt.xlabel('Total Evaluators')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79c832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:39:23.988023Z",
     "iopub.status.busy": "2024-02-20T13:39:23.987672Z",
     "iopub.status.idle": "2024-02-20T13:39:24.473279Z",
     "shell.execute_reply": "2024-02-20T13:39:24.472221Z"
    },
    "papermill": {
     "duration": 0.501407,
     "end_time": "2024-02-20T13:39:24.475606",
     "exception": false,
     "start_time": "2024-02-20T13:39:23.974199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eeg_df = pd.read_parquet(CFG.data_root + \"100261680.parquet\")\n",
    "eeg_features = eeg_df.columns\n",
    "print(f'There are {len(eeg_features)} raw eeg features')\n",
    "print(list(eeg_features))\n",
    "eeg_features = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "feature_to_index = {x:y for x,y in zip(eeg_features, range(len(eeg_features)))}\n",
    "\n",
    "del eeg_df\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec2891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:39:24.502794Z",
     "iopub.status.busy": "2024-02-20T13:39:24.502463Z",
     "iopub.status.idle": "2024-02-20T13:40:45.672752Z",
     "shell.execute_reply": "2024-02-20T13:40:45.671752Z"
    },
    "papermill": {
     "duration": 81.197926,
     "end_time": "2024-02-20T13:40:45.686597",
     "exception": false,
     "start_time": "2024-02-20T13:39:24.488671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_eeg_specs = np.load('/kaggle/input/eeg-spectrogram-by-lead-id-unique/eeg_specs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f356c",
   "metadata": {
    "papermill": {
     "duration": 0.011363,
     "end_time": "2024-02-20T13:40:45.709831",
     "exception": false,
     "start_time": "2024-02-20T13:40:45.698468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deduplicate Train EEG Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad534c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:40:45.734068Z",
     "iopub.status.busy": "2024-02-20T13:40:45.733538Z",
     "iopub.status.idle": "2024-02-20T13:40:46.274120Z",
     "shell.execute_reply": "2024-02-20T13:40:46.273123Z"
    },
    "papermill": {
     "duration": 0.555029,
     "end_time": "2024-02-20T13:40:46.276155",
     "exception": false,
     "start_time": "2024-02-20T13:40:45.721126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train[train['label_id'].isin(all_eeg_specs.keys())].copy()\n",
    "pop_1_idx = train['total_evaluators'] < 10\n",
    "\n",
    "y_data = train[TARGETS].values +  0.166666667 # Regularization value\n",
    "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "train[TARGETS] = y_data\n",
    "\n",
    "train['target'] = train['expert_consensus']\n",
    "    \n",
    "train_pop_1 = train.copy()\n",
    "# train_pop_1 = train[pop_1_idx].copy().reset_index()\n",
    "# train_pop_2 = train[~pop_1_idx].copy().reset_index()\n",
    "\n",
    "print('Pop 1: train unique eeg_id + votes shape:', train_pop_1.shape )\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train['total_evaluators'], bins=10, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Total Evaluators')\n",
    "plt.xlabel('Total Evaluators')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "del all_eeg_specs\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8076f6",
   "metadata": {
    "papermill": {
     "duration": 0.012537,
     "end_time": "2024-02-20T13:40:46.301221",
     "exception": false,
     "start_time": "2024-02-20T13:40:46.288684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3587e4",
   "metadata": {
    "papermill": {
     "duration": 0.012579,
     "end_time": "2024-02-20T13:40:46.326688",
     "exception": false,
     "start_time": "2024-02-20T13:40:46.314109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CV Scheme pop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31965c30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:40:46.353787Z",
     "iopub.status.busy": "2024-02-20T13:40:46.353156Z",
     "iopub.status.idle": "2024-02-20T13:40:46.375654Z",
     "shell.execute_reply": "2024-02-20T13:40:46.374935Z"
    },
    "papermill": {
     "duration": 0.03823,
     "end_time": "2024-02-20T13:40:46.377688",
     "exception": false,
     "start_time": "2024-02-20T13:40:46.339458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sgkf = GroupKFold(n_splits=CFG.n_fold)\n",
    "\n",
    "# train_pop_1[\"fold\"] = -1\n",
    "\n",
    "# for fold_id, (_, val_idx) in enumerate(\n",
    "#     sgkf.split(train_pop_1, y=train_pop_1[\"target\"], groups=train_pop_1[\"patient_id\"])\n",
    "# ):\n",
    "#     train_pop_1.loc[val_idx, \"fold\"] = fold_id\n",
    "\n",
    "import yaml\n",
    "for fold in range(5):\n",
    "    valid_ids_path = f\"/kaggle/input/valid_eeg_ids_fold{fold}.yaml\"\n",
    "    with open(valid_ids_path, 'r') as file:\n",
    "        valid_ids = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    train_pop_1.loc[train_pop_1['eeg_id'].isin(valid_ids), 'fold'] = fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e3d340",
   "metadata": {
    "papermill": {
     "duration": 0.054287,
     "end_time": "2024-02-20T13:40:46.444585",
     "exception": false,
     "start_time": "2024-02-20T13:40:46.390298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CV Scheme pop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2f9c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:40:46.470869Z",
     "iopub.status.busy": "2024-02-20T13:40:46.470556Z",
     "iopub.status.idle": "2024-02-20T13:40:46.486543Z",
     "shell.execute_reply": "2024-02-20T13:40:46.485802Z"
    },
    "papermill": {
     "duration": 0.031145,
     "end_time": "2024-02-20T13:40:46.488516",
     "exception": false,
     "start_time": "2024-02-20T13:40:46.457371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sgkf = GroupKFold(n_splits=CFG.n_fold)\n",
    "\n",
    "# train_pop_2[\"fold\"] = -1\n",
    "\n",
    "# for fold_id, (_, val_idx) in enumerate(\n",
    "#     sgkf.split(train_pop_2, y=train_pop_2[\"target\"], groups=train_pop_2[\"patient_id\"])\n",
    "# ):\n",
    "#     train_pop_2.loc[val_idx, \"fold\"] = fold_id\n",
    "\n",
    "# import yaml\n",
    "# for fold in range(5):\n",
    "#     valid_ids_path = f\"/kaggle/input/valid_eeg_ids_fold{fold}.yaml\"\n",
    "#     with open(valid_ids_path, 'r') as file:\n",
    "#         valid_ids = yaml.load(file, Loader=yaml.FullLoader)\n",
    "#     train_pop_2.loc[train_pop_2['eeg_id'].isin(valid_ids), 'fold'] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc4be24",
   "metadata": {
    "papermill": {
     "duration": 0.011709,
     "end_time": "2024-02-20T13:40:46.512143",
     "exception": false,
     "start_time": "2024-02-20T13:40:46.500434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parquet to EEG Signals Numpy Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebfdf33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:40:46.538575Z",
     "iopub.status.busy": "2024-02-20T13:40:46.537913Z",
     "iopub.status.idle": "2024-02-20T13:40:46.548666Z",
     "shell.execute_reply": "2024-02-20T13:40:46.547909Z"
    },
    "papermill": {
     "duration": 0.026463,
     "end_time": "2024-02-20T13:40:46.550473",
     "exception": false,
     "start_time": "2024-02-20T13:40:46.524010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eeg_from_parquet(parquet_path: str, display: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function reads a parquet file and extracts the middle 50 seconds of readings. Then it fills NaN values\n",
    "    with the mean value (ignoring NaNs).\n",
    "    :param parquet_path: path to parquet file.\n",
    "    :param display: whether to display EEG plots or not.\n",
    "    :return data: np.array of shape  (time_steps, eeg_features) -> (10_000, 8)\n",
    "    \"\"\"\n",
    "    # === Extract middle 50 seconds ===\n",
    "    eeg = pd.read_parquet(parquet_path, columns=eeg_features)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n",
    "    eeg = eeg.iloc[offset:offset+10_000] # middle 50 seconds, has the same amount of readings to left and right\n",
    "    if display: \n",
    "        plt.figure(figsize=(10,5))\n",
    "        offset = 0\n",
    "    # === Convert to numpy ===\n",
    "    data = np.zeros((10_000, len(eeg_features))) # create placeholder of same shape with zeros\n",
    "    for index, feature in enumerate(eeg_features):\n",
    "        x = eeg[feature].values.astype('float32') # convert to float32\n",
    "        mean = np.nanmean(x) # arithmetic mean along the specified axis, ignoring NaNs\n",
    "        nan_percentage = np.isnan(x).mean() # percentage of NaN values in feature\n",
    "        # === Fill nan values ===\n",
    "        if nan_percentage < 1: # if some values are nan, but not all\n",
    "            x = np.nan_to_num(x, nan=mean)\n",
    "        else: # if all values are nan\n",
    "            x[:] = 0\n",
    "        data[:, index] = x\n",
    "        if display: \n",
    "            if index != 0:\n",
    "                offset += x.max()\n",
    "            plt.plot(range(10_000), x-offset, label=feature)\n",
    "            offset -= x.min()\n",
    "    if display:\n",
    "        plt.legend()\n",
    "        name = parquet_path.split('/')[-1].split('.')[0]\n",
    "        plt.yticks([])\n",
    "        plt.title(f'EEG {name}',size=16)\n",
    "        plt.show()    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0f6d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:40:46.575466Z",
     "iopub.status.busy": "2024-02-20T13:40:46.575194Z",
     "iopub.status.idle": "2024-02-20T13:42:17.865644Z",
     "shell.execute_reply": "2024-02-20T13:42:17.864549Z"
    },
    "papermill": {
     "duration": 91.32162,
     "end_time": "2024-02-20T13:42:17.883979",
     "exception": false,
     "start_time": "2024-02-20T13:40:46.562359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "CREATE_EEGS = False\n",
    "all_eegs = {}\n",
    "visualize = 1\n",
    "eeg_paths = glob(CFG.data_root + \"*.parquet\")\n",
    "eeg_ids = train.eeg_id.unique()\n",
    "\n",
    "for i, eeg_id in tqdm(enumerate(eeg_ids)):  \n",
    "    # Save EEG to Python dictionary of numpy arrays\n",
    "    eeg_path = CFG.data_root + str(eeg_id) + \".parquet\"\n",
    "    data = eeg_from_parquet(eeg_path, display=i<visualize)              \n",
    "    all_eegs[eeg_id] = data\n",
    "    \n",
    "    if i == visualize:\n",
    "        if CREATE_EEGS:\n",
    "            print(f'Processing {train_df.eeg_id.nunique()} eeg parquets... ',end='')\n",
    "        else:\n",
    "            print(f'Reading {len(eeg_ids)} eeg NumPys from disk.')\n",
    "            break\n",
    "            \n",
    "if CREATE_EEGS: \n",
    "    np.save('eegs', all_eegs)\n",
    "else:\n",
    "    all_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f3ed7",
   "metadata": {
    "papermill": {
     "duration": 0.014802,
     "end_time": "2024-02-20T13:42:17.914507",
     "exception": false,
     "start_time": "2024-02-20T13:42:17.899705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3eee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:17.943814Z",
     "iopub.status.busy": "2024-02-20T13:42:17.943506Z",
     "iopub.status.idle": "2024-02-20T13:42:17.962159Z",
     "shell.execute_reply": "2024-02-20T13:42:17.961453Z"
    },
    "papermill": {
     "duration": 0.0354,
     "end_time": "2024-02-20T13:42:17.964068",
     "exception": false,
     "start_time": "2024-02-20T13:42:17.928668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x#quantized\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame, config, mode: str = 'train',\n",
    "        eegs: Dict[int, np.ndarray] = all_eegs, downsample: int = None\n",
    "    ): \n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.batch_size = self.config.batch_size\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        X, y_prob = self.__data_generation(index)\n",
    "        if self.downsample is not None:\n",
    "            X = X[::self.downsample,:]\n",
    "        output = {\n",
    "            \"eeg\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(y_prob, dtype=torch.float32)\n",
    "        }\n",
    "        return output\n",
    "                        \n",
    "    def __data_generation(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        X = np.zeros((10_000, 8), dtype='float32')\n",
    "        y = np.zeros(6, dtype='float32')\n",
    "        data = self.eegs[row.eeg_id]\n",
    "\n",
    "        # === Feature engineering ===\n",
    "        X[:,0] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['T3']]\n",
    "        X[:,1] = data[:,feature_to_index['T3']] - data[:,feature_to_index['O1']]\n",
    "\n",
    "        X[:,2] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['C3']]\n",
    "        X[:,3] = data[:,feature_to_index['C3']] - data[:,feature_to_index['O1']]\n",
    "\n",
    "        X[:,4] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['C4']]\n",
    "        X[:,5] = data[:,feature_to_index['C4']] - data[:,feature_to_index['O2']]\n",
    "\n",
    "        X[:,6] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['T4']]\n",
    "        X[:,7] = data[:,feature_to_index['T4']] - data[:,feature_to_index['O2']]\n",
    "\n",
    "        # === Standarize ===\n",
    "        X = np.clip(X,-1024, 1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        # === Butter Low-pass Filter ===\n",
    "        X = butter_lowpass_filter(X)\n",
    "        if self.mode != 'test':\n",
    "            y_prob = row[self.config.target_cols].values.astype(np.float32)\n",
    "        return X, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d94b40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:17.994273Z",
     "iopub.status.busy": "2024-02-20T13:42:17.993590Z",
     "iopub.status.idle": "2024-02-20T13:42:18.591360Z",
     "shell.execute_reply": "2024-02-20T13:42:18.590409Z"
    },
    "papermill": {
     "duration": 0.617175,
     "end_time": "2024-02-20T13:42:18.595502",
     "exception": false,
     "start_time": "2024-02-20T13:42:17.978327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "frequencies = [1,2,4,8,16][::-1] # frequencies in Hz\n",
    "x = [all_eegs[eeg_ids[0]][:,0]] # select one EEG feature\n",
    "\n",
    "for frequency in frequencies:\n",
    "    x.append(butter_lowpass_filter(x[0], cutoff_freq=frequency))\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(10_000), x[0], label='without filter')\n",
    "for k in range(1,len(x)):\n",
    "    plt.plot(range(10_000),x[k]-k*(x[0].max()-x[0].min()), label=f'with filter {frequencies[k-1]}Hz')\n",
    "\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.title('Butter Low-Pass Filter Examples',size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c06805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:18.632100Z",
     "iopub.status.busy": "2024-02-20T13:42:18.631757Z",
     "iopub.status.idle": "2024-02-20T13:42:18.667002Z",
     "shell.execute_reply": "2024-02-20T13:42:18.665931Z"
    },
    "papermill": {
     "duration": 0.055944,
     "end_time": "2024-02-20T13:42:18.669090",
     "exception": false,
     "start_time": "2024-02-20T13:42:18.613146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = EEGDataset(train_pop_1, CFG, mode=\"train\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.num_workers, pin_memory=True, drop_last=True\n",
    ")\n",
    "output = train_dataset[0]\n",
    "X, y = output[\"eeg\"], output[\"labels\"]\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec3d80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:18.705539Z",
     "iopub.status.busy": "2024-02-20T13:42:18.705200Z",
     "iopub.status.idle": "2024-02-20T13:42:28.691941Z",
     "shell.execute_reply": "2024-02-20T13:42:28.690636Z"
    },
    "papermill": {
     "duration": 10.006792,
     "end_time": "2024-02-20T13:42:28.694429",
     "exception": false,
     "start_time": "2024-02-20T13:42:18.687637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.visualize:\n",
    "    for batch in train_loader:\n",
    "        X = batch.pop(\"eeg\")\n",
    "        y = batch.pop(\"labels\")\n",
    "        for item in range(4):\n",
    "            plt.figure(figsize=(20,4))\n",
    "            offset = 0\n",
    "            for col in range(X.shape[-1]):\n",
    "                if col != 0:\n",
    "                    offset -= X[item,:,col].min()\n",
    "                plt.plot(range(10_000), X[item,:,col]+offset,label=f'feature {col+1}')\n",
    "                offset += X[item,:,col].max()\n",
    "            tt = f'{y[col][0]:0.1f}'\n",
    "            for t in y[col][1:]:\n",
    "                tt += f', {t:0.1f}'\n",
    "            plt.title(f'EEG_Id = {eeg_ids[item]}\\nTarget = {tt}',size=14)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ecbbf8",
   "metadata": {
    "papermill": {
     "duration": 0.031018,
     "end_time": "2024-02-20T13:42:28.757460",
     "exception": false,
     "start_time": "2024-02-20T13:42:28.726442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28e6532",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:28.820219Z",
     "iopub.status.busy": "2024-02-20T13:42:28.819862Z",
     "iopub.status.idle": "2024-02-20T13:42:28.842869Z",
     "shell.execute_reply": "2024-02-20T13:42:28.842124Z"
    },
    "papermill": {
     "duration": 0.05674,
     "end_time": "2024-02-20T13:42:28.844768",
     "exception": false,
     "start_time": "2024-02-20T13:42:28.788028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet_1D_Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, downsampling):\n",
    "        super(ResNet_1D_Block, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.dropout = nn.Dropout(p=0.0, inplace=False)\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                               stride=stride, padding=padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                               stride=stride, padding=padding, bias=False)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        identity = self.downsampling(x)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "\n",
    "    def __init__(self, kernels, in_channels=20, fixed_kernel_size=17, num_classes=6):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        for i, kernel_size in enumerate(list(self.kernels)):\n",
    "            sep_conv = nn.Conv1d(in_channels=in_channels, out_channels=self.planes, kernel_size=(kernel_size),\n",
    "                               stride=1, padding=0, bias=False,)\n",
    "            self.parallel_conv.append(sep_conv)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.planes, out_channels=self.planes, kernel_size=fixed_kernel_size,\n",
    "                               stride=2, padding=2, bias=False)\n",
    "        self.block = self._make_resnet_layer(kernel_size=fixed_kernel_size, stride=1, padding=fixed_kernel_size//2)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n",
    "        self.rnn = nn.GRU(input_size=self.in_channels, hidden_size=128, num_layers=1, bidirectional=True)\n",
    "        self.fc = nn.Linear(in_features=424, out_features=num_classes)\n",
    "\n",
    "    def _make_resnet_layer(self, kernel_size, stride, blocks=9, padding=0):\n",
    "        layers = []\n",
    "        downsample = None\n",
    "        base_width = self.planes\n",
    "\n",
    "        for i in range(blocks):\n",
    "            downsampling = nn.Sequential(\n",
    "                    nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "                )\n",
    "            layers.append(ResNet_1D_Block(in_channels=self.planes, out_channels=self.planes, kernel_size=kernel_size,\n",
    "                                       stride=stride, padding=padding, downsampling=downsampling))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out_sep = []\n",
    "\n",
    "        for i in range(len(self.kernels)):\n",
    "            sep = self.parallel_conv[i](x)\n",
    "            out_sep.append(sep)\n",
    "\n",
    "        out = torch.cat(out_sep, dim=2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)  \n",
    "\n",
    "        out = self.block(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.avgpool(out)  \n",
    "        \n",
    "        out = out.reshape(out.shape[0], -1)  \n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]  \n",
    "\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1) \n",
    "        return new_out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        new_out = self.extract_features(x)\n",
    "        result = self.fc(new_out)  \n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2b5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:28.905660Z",
     "iopub.status.busy": "2024-02-20T13:42:28.905344Z",
     "iopub.status.idle": "2024-02-20T13:42:29.511139Z",
     "shell.execute_reply": "2024-02-20T13:42:29.510133Z"
    },
    "papermill": {
     "duration": 0.638526,
     "end_time": "2024-02-20T13:42:29.513480",
     "exception": false,
     "start_time": "2024-02-20T13:42:28.874954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "iot = torch.randn(2, 10000, 8)#.cuda()\n",
    "model = EEGNet(kernels=[3,5,7,9], in_channels=CFG.in_channels, fixed_kernel_size=5, num_classes=CFG.target_size)\n",
    "output = model(iot)\n",
    "print(output.shape)\n",
    "\n",
    "del iot, model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416220b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:29.576789Z",
     "iopub.status.busy": "2024-02-20T13:42:29.576341Z",
     "iopub.status.idle": "2024-02-20T13:42:29.600941Z",
     "shell.execute_reply": "2024-02-20T13:42:29.600218Z"
    },
    "papermill": {
     "duration": 0.058157,
     "end_time": "2024-02-20T13:42:29.602820",
     "exception": false,
     "start_time": "2024-02-20T13:42:29.544663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "\n",
    "class Adan(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements a pytorch variant of Adan\n",
    "    Adan was proposed in\n",
    "    Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models[J]. arXiv preprint arXiv:2208.06677, 2022.\n",
    "    https://arxiv.org/abs/2208.06677\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining parameter groups.\n",
    "        lr (float, optional): learning rate. (default: 1e-3)\n",
    "        betas (Tuple[float, float, flot], optional): coefficients used for computing \n",
    "            running averages of gradient and its norm. (default: (0.98, 0.92, 0.99))\n",
    "        eps (float, optional): term added to the denominator to improve \n",
    "            numerical stability. (default: 1e-8)\n",
    "        weight_decay (float, optional): decoupled weight decay (L2 penalty) (default: 0)\n",
    "        max_grad_norm (float, optional): value used to clip \n",
    "            global grad norm (default: 0.0 no clip)\n",
    "        no_prox (bool): how to perform the decoupled weight decay (default: False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.98, 0.92, 0.99), eps=1e-8,\n",
    "                 weight_decay=0.2, max_grad_norm=0.0, no_prox=False):\n",
    "        if not 0.0 <= max_grad_norm:\n",
    "            raise ValueError(\"Invalid Max grad norm: {}\".format(max_grad_norm))\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        if not 0.0 <= betas[2] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 2: {}\".format(betas[2]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay,\n",
    "                        max_grad_norm=max_grad_norm, no_prox=no_prox)\n",
    "        super(Adan, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Adan, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('no_prox', False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def restart_opt(self):\n",
    "        for group in self.param_groups:\n",
    "            group['step'] = 0\n",
    "            for p in group['params']:\n",
    "                if p.requires_grad:\n",
    "                    state = self.state[p]\n",
    "                    # State initialization\n",
    "\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p)\n",
    "                    # Exponential moving average of gradient difference\n",
    "                    state['exp_avg_diff'] = torch.zeros_like(p)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "            Performs a single optimization step.\n",
    "        \"\"\"\n",
    "        if self.defaults['max_grad_norm'] > 0:\n",
    "            device = self.param_groups[0]['params'][0].device\n",
    "            global_grad_norm = torch.zeros(1, device=device)\n",
    "\n",
    "            max_grad_norm = torch.tensor(self.defaults['max_grad_norm'], device=device)\n",
    "            for group in self.param_groups:\n",
    "\n",
    "                for p in group['params']:\n",
    "                    if p.grad is not None:\n",
    "                        grad = p.grad\n",
    "                        global_grad_norm.add_(grad.pow(2).sum())\n",
    "\n",
    "            global_grad_norm = torch.sqrt(global_grad_norm)\n",
    "\n",
    "            clip_global_grad_norm = torch.clamp(max_grad_norm / (global_grad_norm + group['eps']), max=1.0)\n",
    "        else:\n",
    "            clip_global_grad_norm = 1.0\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            beta1, beta2, beta3 = group['betas']\n",
    "            # assume same step across group now to simplify things\n",
    "            # per parameter step can be easily support by making it tensor, or pass list into kernel\n",
    "            if 'step' in group:\n",
    "                group['step'] += 1\n",
    "            else:\n",
    "                group['step'] = 1\n",
    "\n",
    "            bias_correction1 = 1.0 - beta1 ** group['step']\n",
    "\n",
    "            bias_correction2 = 1.0 - beta2 ** group['step']\n",
    "\n",
    "            bias_correction3 = 1.0 - beta3 ** group['step']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                state = self.state[p]\n",
    "                if len(state) == 0:\n",
    "                    state['exp_avg'] = torch.zeros_like(p)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p)\n",
    "                    state['exp_avg_diff'] = torch.zeros_like(p)\n",
    "\n",
    "                grad = p.grad.mul_(clip_global_grad_norm)\n",
    "                if 'pre_grad' not in state or group['step'] == 1:\n",
    "                    state['pre_grad'] = grad\n",
    "\n",
    "                copy_grad = grad.clone()\n",
    "\n",
    "                exp_avg, exp_avg_sq, exp_avg_diff = state['exp_avg'], state['exp_avg_sq'], state['exp_avg_diff']\n",
    "                diff = grad - state['pre_grad']\n",
    "\n",
    "                update = grad + beta2 * diff\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)  # m_t\n",
    "                exp_avg_diff.mul_(beta2).add_(diff, alpha=1 - beta2)  # diff_t\n",
    "                exp_avg_sq.mul_(beta3).addcmul_(update, update, value=1 - beta3)  # n_t\n",
    "\n",
    "                denom = ((exp_avg_sq).sqrt() / math.sqrt(bias_correction3)).add_(group['eps'])\n",
    "                update = ((exp_avg / bias_correction1 + beta2 * exp_avg_diff / bias_correction2)).div_(denom)\n",
    "\n",
    "                if group['no_prox']:\n",
    "                    p.data.mul_(1 - group['lr'] * group['weight_decay'])\n",
    "                    p.add_(update, alpha=-group['lr'])\n",
    "                else:\n",
    "                    p.add_(update, alpha=-group['lr'])\n",
    "                    p.data.div_(1 + group['lr'] * group['weight_decay'])\n",
    "\n",
    "                state['pre_grad'] = copy_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53f9f3",
   "metadata": {
    "papermill": {
     "duration": 0.029424,
     "end_time": "2024-02-20T13:42:29.662195",
     "exception": false,
     "start_time": "2024-02-20T13:42:29.632771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d89c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:29.724044Z",
     "iopub.status.busy": "2024-02-20T13:42:29.723496Z",
     "iopub.status.idle": "2024-02-20T13:42:29.744420Z",
     "shell.execute_reply": "2024-02-20T13:42:29.743674Z"
    },
    "papermill": {
     "duration": 0.054714,
     "end_time": "2024-02-20T13:42:29.746397",
     "exception": false,
     "start_time": "2024-02-20T13:42:29.691683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        eegs = batch['eeg'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds= model(eegs)\n",
    "            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    start = end = time.time()\n",
    "    for step, batch in enumerate(valid_loader):\n",
    "        eegs = batch['eeg'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(eegs)\n",
    "            loss = criterion(F.log_softmax(y_preds, dim=1), labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(nn.Softmax(dim=1)(y_preds).to('cpu').numpy())\n",
    "        targets.append(labels.to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712e437",
   "metadata": {
    "papermill": {
     "duration": 0.031254,
     "end_time": "2024-02-20T13:42:29.808216",
     "exception": false,
     "start_time": "2024-02-20T13:42:29.776962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35dd1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:29.872367Z",
     "iopub.status.busy": "2024-02-20T13:42:29.872072Z",
     "iopub.status.idle": "2024-02-20T13:42:29.895963Z",
     "shell.execute_reply": "2024-02-20T13:42:29.895215Z"
    },
    "papermill": {
     "duration": 0.05868,
     "end_time": "2024-02-20T13:42:29.897814",
     "exception": false,
     "start_time": "2024-02-20T13:42:29.839134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold, directory):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[ CFG.target_cols].values\n",
    "    \n",
    "    train_dataset = EEGDataset(train_folds, CFG, mode=\"train\")\n",
    "    valid_dataset = EEGDataset(valid_folds, CFG, mode=\"train\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = EEGNet(kernels=[3,5,7,9], in_channels=CFG.in_channels, fixed_kernel_size=5, num_classes=CFG.target_size)\n",
    "    if CFG.stage2_pop2:\n",
    "        model_weight = POP_1_DIR + f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\"\n",
    "        checkpoint = torch.load(model_weight, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "    model.to(device)\n",
    "    # CPMP: wrap the model to use all GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "    def build_optimizer(cfg, model, device):\n",
    "        lr = cfg.lr\n",
    "        # lr = default_configs[\"lr\"]\n",
    "        if cfg.optimizer == \"SAM\":\n",
    "            base_optimizer = torch.optim.SGD  # define an optimizer for the \"sharpness-aware\" update\n",
    "            optimizer_model = SAM(model.parameters(), base_optimizer, lr=lr, momentum=0.9, weight_decay=cfg.weight_decay, adaptive=True)\n",
    "        elif cfg.optimizer == \"Ranger21\":\n",
    "            optimizer_model = Ranger21(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, \n",
    "            num_epochs=cfg.epochs, num_batches_per_epoch=len(train_loader))\n",
    "        elif cfg.optimizer == \"SGD\":\n",
    "            optimizer_model = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=cfg.weight_decay, momentum=0.9)\n",
    "        elif cfg.optimizer == \"Adam\":\n",
    "            optimizer_model = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n",
    "        elif cfg.optimizer == \"Lion\":\n",
    "            optimizer_model = Lion(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n",
    "        elif cfg.optimizer == \"Adan\":\n",
    "            optimizer_model = Adan(model.parameters(), lr=lr, weight_decay=cfg.weight_decay)\n",
    "    \n",
    "        return optimizer_model\n",
    "    \n",
    "    optimizer = build_optimizer(CFG, model, device)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    # ====================================================\n",
    "\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, **CFG.reduce_params)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, **CFG.cosanneal_params)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, **CFG.cosanneal_res_params)\n",
    "        elif CFG.scheduler=='OneCycleLR':\n",
    "            scheduler = OneCycleLR(optimizer=optimizer, epochs=CFG.epochs, pct_start=0.0, steps_per_epoch=len(train_loader),\n",
    "        max_lr=CFG.lr, div_factor=25, final_div_factor=4.0e-01)\n",
    "        return scheduler\n",
    "    \n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    \n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if best_score > avg_val_loss:\n",
    "            best_score = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best valid loss: {avg_val_loss:.4f} Model')\n",
    "            # CPMP: save the original model. It is stored as the module attribute of the DP model.\n",
    "            if CFG.stage1_pop1:\n",
    "                torch.save({'model': model.module.state_dict(),\n",
    "                            'predictions': predictions},\n",
    "                             directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\")\n",
    "            else:\n",
    "                \n",
    "                torch.save({'model': model.module.state_dict(),\n",
    "                            'predictions': predictions},\n",
    "                             directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\")\n",
    "                \n",
    "    if CFG.stage1_pop1:\n",
    "        predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage1.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    else:\n",
    "        predictions = torch.load(directory+f\"{CFG.model_name}_fold{fold}_best_version{VERSION}_stage2.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
    "    valid_folds[CFG.target_cols] = valid_labels \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca315cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T13:42:29.961601Z",
     "iopub.status.busy": "2024-02-20T13:42:29.961176Z",
     "iopub.status.idle": "2024-02-20T14:26:40.159404Z",
     "shell.execute_reply": "2024-02-20T14:26:40.158522Z"
    },
    "papermill": {
     "duration": 2650.233098,
     "end_time": "2024-02-20T14:26:40.161837",
     "exception": false,
     "start_time": "2024-02-20T13:42:29.928739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    def get_result(result_df):\n",
    "        gt = result_df[[\"eeg_id\"] + CFG.target_cols]\n",
    "        gt.sort_values(by=\"eeg_id\", inplace=True)\n",
    "        gt.reset_index(inplace=True, drop=True)\n",
    "        preds = result_df[[\"eeg_id\"] + CFG.pred_cols]\n",
    "        preds.columns = [\"eeg_id\"] + CFG.target_cols\n",
    "        preds.sort_values(by=\"eeg_id\", inplace=True)\n",
    "        preds.reset_index(inplace=True, drop=True)\n",
    "        score_loss = get_score(gt[CFG.target_cols], preds[CFG.target_cols])\n",
    "        LOGGER.info(f'Score with best loss weights: {score_loss}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        scores = []\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df, score = train_loop(train_pop_1, fold, POP_1_DIR)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                scores.append(score)\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                LOGGER.info(f'Score with best loss weights stage1: {score}')\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        LOGGER.info(f'Score with best loss weights: {np.mean(scores)}')\n",
    "        oof_df.to_csv(POP_1_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage1.csv', index=False)\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result_df):\n",
    "    gt = result_df[[\"eeg_id\"] + CFG.target_cols]\n",
    "    gt.sort_values(by=\"eeg_id\", inplace=True)\n",
    "    gt.reset_index(inplace=True, drop=True)\n",
    "    preds = result_df[[\"eeg_id\"] + CFG.pred_cols]\n",
    "    preds.columns = [\"eeg_id\"] + CFG.target_cols\n",
    "    preds.sort_values(by=\"eeg_id\", inplace=True)\n",
    "    preds.reset_index(inplace=True, drop=True)\n",
    "    score_loss = get_score(gt[CFG.target_cols], preds[CFG.target_cols])\n",
    "    LOGGER.info(f'Score with best loss weights: {score_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d6236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T14:26:40.309882Z",
     "iopub.status.busy": "2024-02-20T14:26:40.308975Z",
     "iopub.status.idle": "2024-02-20T15:08:05.572357Z",
     "shell.execute_reply": "2024-02-20T15:08:05.571444Z"
    },
    "papermill": {
     "duration": 2485.347793,
     "end_time": "2024-02-20T15:08:05.574485",
     "exception": false,
     "start_time": "2024-02-20T14:26:40.226692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CFG.stage2_pop1 = False\n",
    "# CFG.stage3_pop2 = False\n",
    "# CFG.epochs = 21\n",
    "\n",
    "\n",
    "# if CFG.train:\n",
    "#     oof_df = pd.DataFrame()\n",
    "#     scores = []\n",
    "#     for fold in range(CFG.n_fold):\n",
    "#         if fold in CFG.trn_fold:\n",
    "#             _oof_df, score = train_loop(train_pop_3, fold, POP_2_DIR)\n",
    "#             oof_df = pd.concat([oof_df, _oof_df])\n",
    "#             scores.append(score)\n",
    "#             LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "#             LOGGER.info(f'Score with best loss weights stage3: {score}')\n",
    "#     oof_df = oof_df.reset_index(drop=True)\n",
    "#     LOGGER.info(f\"========== CV ==========\")\n",
    "#     LOGGER.info(f'Score with best loss weights: {np.mean(scores)}')\n",
    "#     oof_df.to_csv(POP_3_DIR+f'{CFG.model_name}_oof_df_version{VERSION}_stage2.csv', index=False)\n",
    "    \n",
    "# if CFG.wandb:\n",
    "#     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d83d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T15:08:05.806941Z",
     "iopub.status.busy": "2024-02-20T15:08:05.806565Z",
     "iopub.status.idle": "2024-02-20T15:08:05.858070Z",
     "shell.execute_reply": "2024-02-20T15:08:05.857038Z"
    },
    "papermill": {
     "duration": 0.167828,
     "end_time": "2024-02-20T15:08:05.860071",
     "exception": false,
     "start_time": "2024-02-20T15:08:05.692243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/kaggle/src\")\n",
    "from kaggle_metrics.kaggle_kl_div import competition_score\n",
    "\n",
    "# === Pre-process OOF ===\n",
    "label_cols = CFG.target_cols\n",
    "gt = oof_df[[\"eeg_id\"] + CFG.target_cols]\n",
    "gt.sort_values(by=\"eeg_id\", inplace=True)\n",
    "gt.reset_index(inplace=True, drop=True)\n",
    "\n",
    "preds = oof_df[[\"eeg_id\"] + CFG.pred_cols]\n",
    "preds.columns = [\"eeg_id\"] + CFG.target_cols\n",
    "preds.sort_values(by=\"eeg_id\", inplace=True)\n",
    "preds.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y_trues = gt[CFG.target_cols]\n",
    "y_preds = preds[CFG.target_cols]\n",
    "\n",
    "oof = pd.DataFrame(y_preds.copy())\n",
    "oof['id'] = np.arange(len(oof))\n",
    "\n",
    "true = pd.DataFrame(y_trues.copy())\n",
    "true['id'] = np.arange(len(true))\n",
    "\n",
    "# cv = competition_score(solution=true, submission=oof, row_id_column_name='id')\n",
    "cv = competition_score(solution=true, submission=oof)\n",
    "print('CV Score with resnet1D_gru Raw EEG =',cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc22a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297749,
     "sourceId": 7392733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4317718,
     "sourceId": 7465251,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4378712,
     "sourceId": 7517324,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5345.179582,
   "end_time": "2024-02-20T15:08:09.804733",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-20T13:39:04.625151",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "088fc3f5e4264683bbeaa2d929fab599": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2c3d333449fb412dbc86ca31835ef4b0",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3ba5491929cf4cb1bbb8e28514933aa6",
       "value": 1
      }
     },
     "11bfd3544cf8411e96cd7ede1451518c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5246ec5881c147f09c90846e9911dda6",
       "placeholder": "​",
       "style": "IPY_MODEL_db8fdfb810194e03b66c7c5e5077ccf5",
       "value": " 1/? [00:00&lt;00:00,  1.37it/s]"
      }
     },
     "2c3d333449fb412dbc86ca31835ef4b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "3ba5491929cf4cb1bbb8e28514933aa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5246ec5881c147f09c90846e9911dda6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58eb07f979fd49e8a9155ad60c77923c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "993085d825a542b1b5c44cd42f7f8c89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c818523154ec45689615162b4c03bf96",
        "IPY_MODEL_088fc3f5e4264683bbeaa2d929fab599",
        "IPY_MODEL_11bfd3544cf8411e96cd7ede1451518c"
       ],
       "layout": "IPY_MODEL_fa70a85db4944741a7d7b13cef19bb70"
      }
     },
     "c818523154ec45689615162b4c03bf96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_58eb07f979fd49e8a9155ad60c77923c",
       "placeholder": "​",
       "style": "IPY_MODEL_ea4dcc5f4fcf4011a7ba7dc587109a9b",
       "value": ""
      }
     },
     "db8fdfb810194e03b66c7c5e5077ccf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ea4dcc5f4fcf4011a7ba7dc587109a9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fa70a85db4944741a7d7b13cef19bb70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
